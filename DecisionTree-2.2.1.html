
<!doctype html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>DecisionTree-2.2.1.html</title>
</head><body bgcolor="#f0f0f8">
<tt>

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module DecisionTree</title>
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong>DecisionTree</strong></big></big> (version 2.2.1, 2013-September-5)</font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial">

<!--
<a href=".">index</a><br><a href="file:/home/kak/DecisionTree_py/DecisionTree-2.2.1/DecisionTree.py">/home/kak/DecisionTree_py/DecisionTree-2.2.1/DecisionTree.py</a>
-->

</font></td></tr></table>
    <p><tt><a href="#DecisionTree">DecisionTree</a>.py<br>
&nbsp;<br>
Version:&nbsp;2.2.1<br>
&nbsp;&nbsp;&nbsp;<br>
Author:&nbsp;Avinash&nbsp;Kak&nbsp;(kak@purdue.edu)<br>
&nbsp;<br>
Date:&nbsp;2013-September-5<br>
&nbsp;<br>
&nbsp;<br>
<b>Download Version 2.2.1:</b>
&nbsp;  
<a HREF="https://engineering.purdue.edu/kak/distDT/DecisionTree-2.2.1.tar.gz?download">gztar</a> 
&nbsp;             
<a HREF="https://engineering.purdue.edu/kak/distDT/DecisionTree-2.2.1.tar.bz2?download">bztar</a> 
&nbsp;<br>
&nbsp;<br>
<a HREF="DecisionTree-2.2.1_CodeOnly.html">View version 2.2.1 code in browser</a> 
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">CHANGES:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.2.1:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;changes&nbsp;made&nbsp;are&nbsp;all&nbsp;in&nbsp;the&nbsp;part&nbsp;of&nbsp;the&nbsp;module&nbsp;that&nbsp;is&nbsp;used&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;evaluating&nbsp;the&nbsp;quality&nbsp;of&nbsp;training&nbsp;data&nbsp;through&nbsp;a&nbsp;10-fold&nbsp;cross<br>
&nbsp;&nbsp;&nbsp;&nbsp;validation&nbsp;test.&nbsp;&nbsp;The&nbsp;previous&nbsp;version&nbsp;used&nbsp;the&nbsp;default&nbsp;values&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;parameters&nbsp;when&nbsp;constructing&nbsp;the&nbsp;decision&nbsp;trees&nbsp;in&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;iteration&nbsp;of&nbsp;the&nbsp;test.&nbsp;The&nbsp;new&nbsp;version&nbsp;correctly&nbsp;uses&nbsp;the&nbsp;user-supplied<br>
&nbsp;&nbsp;&nbsp;&nbsp;values.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.2:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;fixes&nbsp;a&nbsp;bug&nbsp;discovered&nbsp;in&nbsp;the&nbsp;best&nbsp;feature&nbsp;calculator<br>
&nbsp;&nbsp;&nbsp;&nbsp;function.&nbsp;This&nbsp;bug&nbsp;was&nbsp;triggered&nbsp;by&nbsp;certain&nbsp;conditions&nbsp;related&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;distribution&nbsp;of&nbsp;values&nbsp;for&nbsp;the&nbsp;features&nbsp;in&nbsp;a&nbsp;training&nbsp;data&nbsp;file.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Additionally,&nbsp;and&nbsp;VERY&nbsp;IMPORTANTLY,&nbsp;Version&nbsp;2.2&nbsp;allows&nbsp;you&nbsp;to&nbsp;test&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;quality&nbsp;of&nbsp;your&nbsp;training&nbsp;data&nbsp;by&nbsp;running&nbsp;a&nbsp;10-fold&nbsp;cross-validation<br>
&nbsp;&nbsp;&nbsp;&nbsp;test&nbsp;on&nbsp;the&nbsp;data.&nbsp;&nbsp;This&nbsp;test&nbsp;divides&nbsp;all&nbsp;of&nbsp;the&nbsp;training&nbsp;data&nbsp;into&nbsp;ten<br>
&nbsp;&nbsp;&nbsp;&nbsp;parts,&nbsp;with&nbsp;nine&nbsp;parts&nbsp;used&nbsp;for&nbsp;training&nbsp;a&nbsp;decision&nbsp;tree&nbsp;and&nbsp;one&nbsp;part<br>
&nbsp;&nbsp;&nbsp;&nbsp;used&nbsp;for&nbsp;testing&nbsp;its&nbsp;ability&nbsp;to&nbsp;classify&nbsp;correctly.&nbsp;This&nbsp;selection&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;nine&nbsp;parts&nbsp;for&nbsp;training&nbsp;and&nbsp;one&nbsp;part&nbsp;for&nbsp;testing&nbsp;is&nbsp;carried&nbsp;out&nbsp;in&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;ten&nbsp;different&nbsp;possible&nbsp;ways.&nbsp;&nbsp;This&nbsp;testing&nbsp;functionality&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;Version&nbsp;2.2&nbsp;can&nbsp;also&nbsp;be&nbsp;used&nbsp;to&nbsp;find&nbsp;the&nbsp;best&nbsp;values&nbsp;to&nbsp;use&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;parameters&nbsp;entropy_threshold,&nbsp;max_depth_desired,&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolic_to_numeric_cardinality_threshold.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.1:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;a&nbsp;cleaned&nbsp;up&nbsp;version&nbsp;of&nbsp;v.&nbsp;2.0&nbsp;of&nbsp;the&nbsp;module.&nbsp;Should&nbsp;run&nbsp;more<br>
&nbsp;&nbsp;&nbsp;&nbsp;efficiently&nbsp;for&nbsp;large&nbsp;training&nbsp;data&nbsp;files&nbsp;that&nbsp;contain&nbsp;both&nbsp;numeric&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolic&nbsp;features.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.0:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;a&nbsp;major&nbsp;rewrite&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module.&nbsp;&nbsp;This&nbsp;revision&nbsp;was<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompted&nbsp;by&nbsp;a&nbsp;number&nbsp;of&nbsp;users&nbsp;wanting&nbsp;to&nbsp;see&nbsp;numeric&nbsp;features<br>
&nbsp;&nbsp;&nbsp;&nbsp;incorporated&nbsp;in&nbsp;the&nbsp;construction&nbsp;of&nbsp;decision&nbsp;trees.&nbsp;&nbsp;So&nbsp;here&nbsp;it&nbsp;is!<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;allows&nbsp;you&nbsp;to&nbsp;use&nbsp;either&nbsp;purely&nbsp;symbolic&nbsp;features,&nbsp;or<br>
&nbsp;&nbsp;&nbsp;&nbsp;purely&nbsp;numeric&nbsp;features,&nbsp;or&nbsp;a&nbsp;mixture&nbsp;of&nbsp;the&nbsp;two.&nbsp;(A&nbsp;feature&nbsp;is&nbsp;numeric<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;it&nbsp;can&nbsp;take&nbsp;any&nbsp;floating-point&nbsp;value&nbsp;over&nbsp;an&nbsp;interval.)<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.7.1:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;includes&nbsp;a&nbsp;fix&nbsp;for&nbsp;a&nbsp;bug&nbsp;that&nbsp;was&nbsp;triggered&nbsp;by&nbsp;certain<br>
&nbsp;&nbsp;&nbsp;&nbsp;comment&nbsp;words&nbsp;in&nbsp;a&nbsp;training&nbsp;data&nbsp;file.&nbsp;&nbsp;This&nbsp;version&nbsp;also&nbsp;includes<br>
&nbsp;&nbsp;&nbsp;&nbsp;additional&nbsp;safety&nbsp;checks&nbsp;that&nbsp;are&nbsp;useful&nbsp;for&nbsp;catching&nbsp;errors&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;inconsistencies&nbsp;in&nbsp;large&nbsp;training&nbsp;data&nbsp;files&nbsp;that&nbsp;do&nbsp;not&nbsp;lend<br>
&nbsp;&nbsp;&nbsp;&nbsp;themselves&nbsp;to&nbsp;manual&nbsp;checking&nbsp;for&nbsp;correctness.&nbsp;&nbsp;As&nbsp;an&nbsp;example,&nbsp;the&nbsp;new<br>
&nbsp;&nbsp;&nbsp;&nbsp;version&nbsp;makes&nbsp;sure&nbsp;that&nbsp;the&nbsp;number&nbsp;of&nbsp;values&nbsp;you&nbsp;declare&nbsp;in&nbsp;each&nbsp;sample<br>
&nbsp;&nbsp;&nbsp;&nbsp;record&nbsp;matches&nbsp;the&nbsp;number&nbsp;of&nbsp;features&nbsp;declared&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data&nbsp;file.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.7:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;includes&nbsp;safety&nbsp;checks&nbsp;on&nbsp;the&nbsp;consistency&nbsp;of&nbsp;the&nbsp;data&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;place&nbsp;in&nbsp;your&nbsp;training&nbsp;data&nbsp;file.&nbsp;&nbsp;When&nbsp;a&nbsp;training&nbsp;data&nbsp;file&nbsp;contains<br>
&nbsp;&nbsp;&nbsp;&nbsp;thousands&nbsp;of&nbsp;records,&nbsp;it&nbsp;is&nbsp;difficult&nbsp;to&nbsp;manually&nbsp;check&nbsp;that&nbsp;you&nbsp;used<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;same&nbsp;class&nbsp;names&nbsp;in&nbsp;your&nbsp;sample&nbsp;records&nbsp;that&nbsp;you&nbsp;declared&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;top&nbsp;of&nbsp;your&nbsp;training&nbsp;file&nbsp;or&nbsp;that&nbsp;the&nbsp;values&nbsp;you&nbsp;have&nbsp;for&nbsp;your&nbsp;features<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;legal&nbsp;vis-a-vis&nbsp;the&nbsp;earlier&nbsp;declarations&nbsp;regarding&nbsp;such&nbsp;values&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;training&nbsp;file.&nbsp;&nbsp;Another&nbsp;safety&nbsp;feature&nbsp;incorporated&nbsp;in&nbsp;this&nbsp;version<br>
&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;the&nbsp;non-consideration&nbsp;of&nbsp;classes&nbsp;that&nbsp;are&nbsp;declared&nbsp;at&nbsp;the&nbsp;top&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;file&nbsp;but&nbsp;that&nbsp;have&nbsp;no&nbsp;sample&nbsp;records&nbsp;in&nbsp;the&nbsp;file.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.6.1:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Fixed&nbsp;a&nbsp;bug&nbsp;in&nbsp;the&nbsp;method&nbsp;that&nbsp;generates&nbsp;synthetic&nbsp;test&nbsp;data.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.6:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;includes&nbsp;several&nbsp;upgrades:&nbsp;The&nbsp;module&nbsp;now&nbsp;includes&nbsp;code<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;generating&nbsp;synthetic&nbsp;training&nbsp;and&nbsp;test&nbsp;data&nbsp;for&nbsp;experimenting&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;classifier.&nbsp;&nbsp;Another&nbsp;upgrade&nbsp;in&nbsp;the&nbsp;new&nbsp;version&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;that,&nbsp;after&nbsp;training,&nbsp;a&nbsp;decision&nbsp;tree&nbsp;can&nbsp;now&nbsp;be&nbsp;used&nbsp;in&nbsp;an&nbsp;interactive<br>
&nbsp;&nbsp;&nbsp;&nbsp;mode&nbsp;in&nbsp;which&nbsp;the&nbsp;user&nbsp;is&nbsp;asked&nbsp;to&nbsp;supply&nbsp;answers&nbsp;for&nbsp;the&nbsp;feature&nbsp;tests<br>
&nbsp;&nbsp;&nbsp;&nbsp;at&nbsp;the&nbsp;nodes&nbsp;as&nbsp;the&nbsp;classification&nbsp;process&nbsp;descends&nbsp;down&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.5:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;a&nbsp;Python&nbsp;3.x&nbsp;compliant&nbsp;version&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module.<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;should&nbsp;work&nbsp;with&nbsp;both&nbsp;Python&nbsp;2.x&nbsp;and&nbsp;Python&nbsp;3.x.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.0:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;a&nbsp;Python&nbsp;implementation&nbsp;of&nbsp;the&nbsp;author's&nbsp;Perl&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;Algorithm::<a href="#DecisionTree">DecisionTree</a>,&nbsp;Version&nbsp;1.41.&nbsp;&nbsp;The&nbsp;Python&nbsp;version&nbsp;should&nbsp;work<br>
&nbsp;&nbsp;&nbsp;&nbsp;faster&nbsp;for&nbsp;large&nbsp;decision&nbsp;trees&nbsp;since&nbsp;it&nbsp;uses&nbsp;probability&nbsp;and&nbsp;entropy<br>
&nbsp;&nbsp;&nbsp;&nbsp;caching&nbsp;much&nbsp;more&nbsp;extensively&nbsp;than&nbsp;Version&nbsp;1.41&nbsp;of&nbsp;the&nbsp;Perl&nbsp;module.<br>
&nbsp;&nbsp;&nbsp;&nbsp;(Note:&nbsp;I&nbsp;expect&nbsp;my&nbsp;next&nbsp;release&nbsp;of&nbsp;the&nbsp;Perl&nbsp;module&nbsp;to&nbsp;catch&nbsp;up&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;Python&nbsp;version&nbsp;in&nbsp;terms&nbsp;of&nbsp;performance.)<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">USAGE:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;your&nbsp;training&nbsp;data&nbsp;includes&nbsp;numeric&nbsp;features&nbsp;(a&nbsp;feature&nbsp;is&nbsp;numeric<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;it&nbsp;can&nbsp;take&nbsp;any&nbsp;floating&nbsp;point&nbsp;value&nbsp;over&nbsp;an&nbsp;interval),&nbsp;you&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;expected&nbsp;to&nbsp;supply&nbsp;your&nbsp;training&nbsp;data&nbsp;through&nbsp;a&nbsp;CSV&nbsp;file&nbsp;and&nbsp;your&nbsp;call<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;constructing&nbsp;a&nbsp;decision&nbsp;tree&nbsp;will&nbsp;look&nbsp;like:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_datafile&nbsp;=&nbsp;"stage3cancer.csv"<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt&nbsp;=&nbsp;<a href="#DecisionTree">DecisionTree</a>.<a href="#DecisionTree">DecisionTree</a>(&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_datafile&nbsp;=&nbsp;training_datafile,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;csv_class_column_index&nbsp;=&nbsp;2,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;csv_columns_for_features&nbsp;=&nbsp;[3,4,5,6,7,8],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entropy_threshold&nbsp;=&nbsp;0.01,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_depth_desired&nbsp;=&nbsp;8,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;symbolic_to_numeric_cardinality_threshold&nbsp;=&nbsp;10,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;constructor&nbsp;option&nbsp;`csv_class_column_index'&nbsp;informs&nbsp;the&nbsp;module&nbsp;as<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;which&nbsp;column&nbsp;of&nbsp;your&nbsp;CSV&nbsp;file&nbsp;contains&nbsp;the&nbsp;class&nbsp;label.&nbsp;&nbsp;THE&nbsp;COLUMN<br>
&nbsp;&nbsp;&nbsp;&nbsp;INDEXING&nbsp;IS&nbsp;ZERO&nbsp;BASED.&nbsp;&nbsp;The&nbsp;constructor&nbsp;option<br>
&nbsp;&nbsp;&nbsp;&nbsp;`csv_columns_for_features'&nbsp;specifies&nbsp;which&nbsp;columns&nbsp;are&nbsp;to&nbsp;be&nbsp;used&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;feature&nbsp;values.&nbsp;&nbsp;The&nbsp;first&nbsp;row&nbsp;of&nbsp;the&nbsp;CSV&nbsp;file&nbsp;must&nbsp;specify&nbsp;the&nbsp;names<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;features.&nbsp;&nbsp;See&nbsp;examples&nbsp;of&nbsp;CSV&nbsp;files&nbsp;in&nbsp;the&nbsp;`examples'<br>
&nbsp;&nbsp;&nbsp;&nbsp;subdirectory.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;option&nbsp;`symbolic_to_numeric_cardinality_threshold'&nbsp;is&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;important.&nbsp;&nbsp;For&nbsp;the&nbsp;example&nbsp;shown&nbsp;above,&nbsp;if&nbsp;an&nbsp;ostensibly&nbsp;numeric<br>
&nbsp;&nbsp;&nbsp;&nbsp;feature&nbsp;takes&nbsp;on&nbsp;only&nbsp;10&nbsp;or&nbsp;fewer&nbsp;different&nbsp;values&nbsp;in&nbsp;your&nbsp;training<br>
&nbsp;&nbsp;&nbsp;&nbsp;datafile,&nbsp;it&nbsp;will&nbsp;be&nbsp;treated&nbsp;like&nbsp;a&nbsp;symbolic&nbsp;feature.&nbsp;&nbsp;The&nbsp;option<br>
&nbsp;&nbsp;&nbsp;&nbsp;`entropy_threshold'&nbsp;determines&nbsp;the&nbsp;granularity&nbsp;with&nbsp;which&nbsp;the&nbsp;entropies<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;sampled&nbsp;for&nbsp;the&nbsp;purpose&nbsp;of&nbsp;calculating&nbsp;entropy&nbsp;gain&nbsp;with&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;particular&nbsp;choice&nbsp;of&nbsp;decision&nbsp;threshold&nbsp;for&nbsp;a&nbsp;numeric&nbsp;feature&nbsp;or&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;feature&nbsp;value&nbsp;for&nbsp;a&nbsp;symbolic&nbsp;feature.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;After&nbsp;you&nbsp;have&nbsp;constructed&nbsp;an&nbsp;instance&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module,&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;read&nbsp;in&nbsp;the&nbsp;training&nbsp;data&nbsp;file&nbsp;and&nbsp;initialize&nbsp;the&nbsp;probability&nbsp;cache&nbsp;by<br>
&nbsp;&nbsp;&nbsp;&nbsp;calling:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.get_training_data()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_first_order_probabilities()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_class_priors()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Now&nbsp;you&nbsp;are&nbsp;ready&nbsp;to&nbsp;construct&nbsp;a&nbsp;decision&nbsp;tree&nbsp;for&nbsp;your&nbsp;training&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;calling:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root_node&nbsp;=&nbsp;dt.construct_decision_tree_classifier()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;root_node&nbsp;is&nbsp;an&nbsp;instance&nbsp;of&nbsp;<a href="#DTNode">DTNode</a>&nbsp;class&nbsp;that&nbsp;is&nbsp;also&nbsp;defined&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;module&nbsp;file.&nbsp;&nbsp;Now&nbsp;you&nbsp;are&nbsp;ready&nbsp;to&nbsp;classify&nbsp;a&nbsp;data&nbsp;record.&nbsp;&nbsp;Let's<br>
&nbsp;&nbsp;&nbsp;&nbsp;say&nbsp;that&nbsp;your&nbsp;data&nbsp;record&nbsp;looks&nbsp;like:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_sample&nbsp;&nbsp;=&nbsp;['g2&nbsp;=&nbsp;4.2',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'grade&nbsp;=&nbsp;2.3',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'gleason&nbsp;=&nbsp;4',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'eet&nbsp;=&nbsp;1.7',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'age&nbsp;=&nbsp;55.0',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'ploidy&nbsp;=&nbsp;diploid']<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;can&nbsp;classify&nbsp;it&nbsp;by&nbsp;calling:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;=&nbsp;dt.classify(root_node,&nbsp;test_sample)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;call&nbsp;to&nbsp;`classify()'&nbsp;returns&nbsp;a&nbsp;reference&nbsp;to&nbsp;a&nbsp;hash&nbsp;whose&nbsp;keys&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;class&nbsp;names&nbsp;and&nbsp;the&nbsp;values&nbsp;the&nbsp;associated&nbsp;classification<br>
&nbsp;&nbsp;&nbsp;&nbsp;probabilities.&nbsp;&nbsp;This&nbsp;hash&nbsp;also&nbsp;includes&nbsp;another&nbsp;key-value&nbsp;pair&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;solution&nbsp;path&nbsp;from&nbsp;the&nbsp;root&nbsp;node&nbsp;to&nbsp;the&nbsp;leaf&nbsp;node&nbsp;at&nbsp;which&nbsp;the&nbsp;final<br>
&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;was&nbsp;carried&nbsp;out.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;your&nbsp;features&nbsp;are&nbsp;purely&nbsp;symbolic,&nbsp;you&nbsp;can&nbsp;continue&nbsp;to&nbsp;use&nbsp;the&nbsp;same<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;syntax&nbsp;that&nbsp;was&nbsp;used&nbsp;in&nbsp;the&nbsp;older&nbsp;versions&nbsp;of&nbsp;this&nbsp;module.<br>
&nbsp;&nbsp;&nbsp;&nbsp;However,&nbsp;your&nbsp;old&nbsp;`.dat'&nbsp;training&nbsp;files&nbsp;will&nbsp;not&nbsp;work&nbsp;with&nbsp;the&nbsp;new<br>
&nbsp;&nbsp;&nbsp;&nbsp;version.&nbsp;&nbsp;The&nbsp;good&nbsp;news&nbsp;is&nbsp;that&nbsp;with&nbsp;just&nbsp;a&nbsp;small&nbsp;fix,&nbsp;you&nbsp;can&nbsp;continue<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;use&nbsp;them.&nbsp;&nbsp;The&nbsp;fix&nbsp;and&nbsp;why&nbsp;it&nbsp;was&nbsp;needed&nbsp;is&nbsp;described&nbsp;in&nbsp;the&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;README_for_dat_files&nbsp;in&nbsp;the&nbsp;`examples'&nbsp;directory.&nbsp;&nbsp;If&nbsp;you&nbsp;are&nbsp;going&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;use&nbsp;a&nbsp;`.dat'&nbsp;file&nbsp;for&nbsp;supplying&nbsp;the&nbsp;training&nbsp;data,&nbsp;your&nbsp;constructor<br>
&nbsp;&nbsp;&nbsp;&nbsp;syntax&nbsp;is&nbsp;likely&nbsp;to&nbsp;look&nbsp;like:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_datafile&nbsp;=&nbsp;"training.dat"<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt&nbsp;=&nbsp;<a href="#DecisionTree">DecisionTree</a>.<a href="#DecisionTree">DecisionTree</a>(&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_datafile&nbsp;=&nbsp;training_datafile,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entropy_threshold&nbsp;=&nbsp;0.01,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_depth_desired&nbsp;=&nbsp;5,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You'd&nbsp;still&nbsp;need&nbsp;to&nbsp;make&nbsp;the&nbsp;following&nbsp;calls&nbsp;for&nbsp;reading&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data,&nbsp;for&nbsp;initializing&nbsp;the&nbsp;probability&nbsp;cache,&nbsp;and&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructing&nbsp;the&nbsp;decision&nbsp;tree:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.get_training_data()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_first_order_probabilities()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_class_priors()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root_node&nbsp;=&nbsp;dt.construct_decision_tree_classifier()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Now&nbsp;your&nbsp;test&nbsp;sample&nbsp;is&nbsp;likely&nbsp;to&nbsp;look&nbsp;like:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_sample&nbsp;=&nbsp;['exercising=never',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'smoking=heavy',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'fatIntake=heavy',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'videoAddiction=heavy']<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You'd&nbsp;now&nbsp;call&nbsp;the&nbsp;calssifier&nbsp;as&nbsp;before:&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;=&nbsp;dt.classify(root_node,&nbsp;test_sample)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;decision&nbsp;tree&nbsp;can&nbsp;quickly&nbsp;become&nbsp;much&nbsp;too&nbsp;large&nbsp;(and&nbsp;much&nbsp;too&nbsp;slow&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;construct&nbsp;and&nbsp;to&nbsp;yield&nbsp;classification&nbsp;results)&nbsp;if&nbsp;the&nbsp;total&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;features&nbsp;is&nbsp;large&nbsp;and/or&nbsp;if&nbsp;the&nbsp;number&nbsp;of&nbsp;different&nbsp;possible&nbsp;values&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;symbolic&nbsp;features&nbsp;is&nbsp;large.&nbsp;&nbsp;You&nbsp;can&nbsp;control&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;through&nbsp;the&nbsp;constructor&nbsp;options&nbsp;`entropy_threshold'&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;`max_depth_desired'.&nbsp;The&nbsp;latter&nbsp;option&nbsp;sets&nbsp;the&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision&nbsp;tree&nbsp;to&nbsp;max_depth_desired&nbsp;value.&nbsp;&nbsp;The&nbsp;parameter<br>
&nbsp;&nbsp;&nbsp;&nbsp;`entropy_threshold'&nbsp;sets&nbsp;the&nbsp;granularity&nbsp;with&nbsp;which&nbsp;the&nbsp;entropies&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;sampled.&nbsp;&nbsp;Its&nbsp;default&nbsp;value&nbsp;is&nbsp;0.001.&nbsp;&nbsp;The&nbsp;larger&nbsp;the&nbsp;value&nbsp;you&nbsp;choose<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;entropy_threshold,&nbsp;the&nbsp;smaller&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">INTRODUCTION:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;is&nbsp;a&nbsp;Python&nbsp;module&nbsp;for&nbsp;constructing&nbsp;a&nbsp;decision&nbsp;tree&nbsp;from&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data&nbsp;file&nbsp;containing&nbsp;multidimensional&nbsp;data&nbsp;in&nbsp;the&nbsp;form&nbsp;of&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;table.&nbsp;In&nbsp;one&nbsp;form&nbsp;or&nbsp;another,&nbsp;decision&nbsp;trees&nbsp;have&nbsp;been&nbsp;around&nbsp;for&nbsp;over<br>
&nbsp;&nbsp;&nbsp;&nbsp;fifty&nbsp;years.&nbsp;From&nbsp;a&nbsp;statistical&nbsp;perspective,&nbsp;they&nbsp;are&nbsp;closely&nbsp;related<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;classification&nbsp;and&nbsp;regression&nbsp;by&nbsp;recursive&nbsp;partitioning&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;multidimensional&nbsp;data.&nbsp;Early&nbsp;work&nbsp;that&nbsp;demonstrated&nbsp;the&nbsp;usefulness&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;such&nbsp;partitioning&nbsp;for&nbsp;classification&nbsp;and&nbsp;regression&nbsp;can&nbsp;be&nbsp;traced,&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;statistics&nbsp;community,&nbsp;to&nbsp;the&nbsp;work&nbsp;of&nbsp;Terry&nbsp;Therneau&nbsp;in&nbsp;the&nbsp;early<br>
&nbsp;&nbsp;&nbsp;&nbsp;1980's&nbsp;and,&nbsp;in&nbsp;the&nbsp;machine&nbsp;learning&nbsp;community,&nbsp;to&nbsp;the&nbsp;work&nbsp;of&nbsp;Ross<br>
&nbsp;&nbsp;&nbsp;&nbsp;Quinlan&nbsp;in&nbsp;the&nbsp;mid&nbsp;1990's.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;those&nbsp;not&nbsp;familiar&nbsp;with&nbsp;decision&nbsp;tree&nbsp;ideas,&nbsp;the&nbsp;traditional&nbsp;way&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;classify&nbsp;multidimensional&nbsp;data&nbsp;is&nbsp;to&nbsp;start&nbsp;with&nbsp;a&nbsp;feature&nbsp;space&nbsp;whose<br>
&nbsp;&nbsp;&nbsp;&nbsp;dimensionality&nbsp;is&nbsp;the&nbsp;same&nbsp;as&nbsp;that&nbsp;of&nbsp;the&nbsp;data.&nbsp;&nbsp;Each&nbsp;feature&nbsp;measures<br>
&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;specific&nbsp;attribute&nbsp;of&nbsp;an&nbsp;entity.&nbsp;&nbsp;You&nbsp;use&nbsp;the&nbsp;training&nbsp;data&nbsp;to&nbsp;carve<br>
&nbsp;&nbsp;&nbsp;&nbsp;up&nbsp;the&nbsp;feature&nbsp;space&nbsp;into&nbsp;different&nbsp;regions,&nbsp;each&nbsp;corresponding&nbsp;to&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;different&nbsp;class.&nbsp;&nbsp;Subsequently,&nbsp;when&nbsp;you&nbsp;try&nbsp;to&nbsp;classify&nbsp;a&nbsp;new&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;sample,&nbsp;you&nbsp;locate&nbsp;it&nbsp;in&nbsp;the&nbsp;feature&nbsp;space&nbsp;and&nbsp;find&nbsp;the&nbsp;class&nbsp;label&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;region&nbsp;to&nbsp;which&nbsp;it&nbsp;belongs.&nbsp;&nbsp;One&nbsp;can&nbsp;also&nbsp;give&nbsp;the&nbsp;data&nbsp;point&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;same&nbsp;class&nbsp;label&nbsp;as&nbsp;that&nbsp;of&nbsp;the&nbsp;nearest&nbsp;training&nbsp;sample.&nbsp;This&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;referred&nbsp;to&nbsp;as&nbsp;the&nbsp;nearest&nbsp;neighbor&nbsp;classification.&nbsp;There&nbsp;exist<br>
&nbsp;&nbsp;&nbsp;&nbsp;hundreds&nbsp;of&nbsp;variations&nbsp;of&nbsp;varying&nbsp;power&nbsp;on&nbsp;this&nbsp;basic&nbsp;approach&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;of&nbsp;multidimensional&nbsp;data.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;decision&nbsp;tree&nbsp;classifier&nbsp;works&nbsp;differently.&nbsp;&nbsp;When&nbsp;you&nbsp;construct&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision&nbsp;tree,&nbsp;you&nbsp;select&nbsp;for&nbsp;the&nbsp;root&nbsp;node&nbsp;a&nbsp;feature&nbsp;test&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;partitions&nbsp;the&nbsp;training&nbsp;data&nbsp;in&nbsp;a&nbsp;way&nbsp;that&nbsp;causes&nbsp;maximal<br>
&nbsp;&nbsp;&nbsp;&nbsp;disambiguation&nbsp;of&nbsp;the&nbsp;class&nbsp;labels&nbsp;associated&nbsp;with&nbsp;the&nbsp;data.&nbsp;&nbsp;In&nbsp;terms<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;information&nbsp;content&nbsp;as&nbsp;measured&nbsp;by&nbsp;entropy,&nbsp;such&nbsp;a&nbsp;feature&nbsp;test<br>
&nbsp;&nbsp;&nbsp;&nbsp;would&nbsp;cause&nbsp;maximum&nbsp;reduction&nbsp;in&nbsp;class&nbsp;entropy&nbsp;in&nbsp;going&nbsp;from&nbsp;all&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data&nbsp;taken&nbsp;together&nbsp;to&nbsp;the&nbsp;data&nbsp;as&nbsp;partitioned&nbsp;by&nbsp;the&nbsp;feature<br>
&nbsp;&nbsp;&nbsp;&nbsp;test.&nbsp;&nbsp;You&nbsp;then&nbsp;drop&nbsp;from&nbsp;the&nbsp;root&nbsp;node&nbsp;a&nbsp;set&nbsp;of&nbsp;child&nbsp;nodes,&nbsp;one&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;each&nbsp;partition&nbsp;of&nbsp;the&nbsp;training&nbsp;data&nbsp;created&nbsp;by&nbsp;the&nbsp;feature&nbsp;test&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;root&nbsp;node.&nbsp;When&nbsp;your&nbsp;features&nbsp;are&nbsp;purely&nbsp;symbolic,&nbsp;you'll&nbsp;have&nbsp;one<br>
&nbsp;&nbsp;&nbsp;&nbsp;child&nbsp;node&nbsp;for&nbsp;each&nbsp;value&nbsp;of&nbsp;the&nbsp;feature&nbsp;chosen&nbsp;for&nbsp;the&nbsp;feature&nbsp;test&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;root.&nbsp;&nbsp;When&nbsp;the&nbsp;test&nbsp;at&nbsp;the&nbsp;root&nbsp;involves&nbsp;a&nbsp;numeric&nbsp;feature,&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;find&nbsp;the&nbsp;decision&nbsp;threshold&nbsp;for&nbsp;the&nbsp;feature&nbsp;that&nbsp;best&nbsp;bipartitions&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;and&nbsp;you&nbsp;drop&nbsp;from&nbsp;the&nbsp;root&nbsp;node&nbsp;two&nbsp;child&nbsp;nodes,&nbsp;one&nbsp;for&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;partition.&nbsp;&nbsp;Now&nbsp;at&nbsp;each&nbsp;child&nbsp;node&nbsp;you&nbsp;pose&nbsp;the&nbsp;same&nbsp;question&nbsp;that&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;posed&nbsp;when&nbsp;you&nbsp;found&nbsp;the&nbsp;best&nbsp;feature&nbsp;to&nbsp;use&nbsp;at&nbsp;the&nbsp;root:&nbsp;Which&nbsp;feature<br>
&nbsp;&nbsp;&nbsp;&nbsp;at&nbsp;the&nbsp;child&nbsp;node&nbsp;in&nbsp;question&nbsp;would&nbsp;maximally&nbsp;disambiguate&nbsp;the&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels&nbsp;associated&nbsp;with&nbsp;the&nbsp;training&nbsp;data&nbsp;corresponding&nbsp;to&nbsp;that&nbsp;child<br>
&nbsp;&nbsp;&nbsp;&nbsp;node?<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;As&nbsp;the&nbsp;reader&nbsp;would&nbsp;expect,&nbsp;the&nbsp;two&nbsp;key&nbsp;steps&nbsp;in&nbsp;any&nbsp;approach&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision-tree&nbsp;based&nbsp;classification&nbsp;are&nbsp;the&nbsp;construction&nbsp;of&nbsp;the&nbsp;decision<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree&nbsp;itself&nbsp;from&nbsp;a&nbsp;file&nbsp;containing&nbsp;the&nbsp;training&nbsp;data,&nbsp;and&nbsp;then&nbsp;using<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;decision&nbsp;tree&nbsp;thus&nbsp;obtained&nbsp;for&nbsp;classifying&nbsp;the&nbsp;data.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;What&nbsp;is&nbsp;cool&nbsp;about&nbsp;decision&nbsp;tree&nbsp;classification&nbsp;is&nbsp;that&nbsp;it&nbsp;gives&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;soft&nbsp;classification,&nbsp;meaning&nbsp;it&nbsp;may&nbsp;associate&nbsp;more&nbsp;than&nbsp;one&nbsp;class&nbsp;label<br>
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;a&nbsp;given&nbsp;data&nbsp;vector.&nbsp;&nbsp;When&nbsp;this&nbsp;happens,&nbsp;it&nbsp;may&nbsp;mean&nbsp;that&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;are&nbsp;indeed&nbsp;overlapping&nbsp;in&nbsp;the&nbsp;underlying&nbsp;feature&nbsp;space.&nbsp;&nbsp;It<br>
&nbsp;&nbsp;&nbsp;&nbsp;could&nbsp;also&nbsp;mean&nbsp;that&nbsp;you&nbsp;simply&nbsp;have&nbsp;not&nbsp;supplied&nbsp;sufficient&nbsp;training<br>
&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;to&nbsp;the&nbsp;decision&nbsp;tree&nbsp;classifier.&nbsp;&nbsp;For&nbsp;a&nbsp;tutorial&nbsp;introduction&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;how&nbsp;a&nbsp;decision&nbsp;tree&nbsp;is&nbsp;constructed&nbsp;and&nbsp;used,&nbsp;see<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://engineering.purdue.edu/kak/Tutorials/DecisionTreeClassifiers.pdf">https://engineering.purdue.edu/kak/Tutorials/DecisionTreeClassifiers.pdf</a><br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">WHAT&nbsp;PRACTICAL&nbsp;PROBLEM&nbsp;IS&nbsp;SOLVED&nbsp;BY&nbsp;THIS&nbsp;MODULE?<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;are&nbsp;new&nbsp;to&nbsp;the&nbsp;concept&nbsp;of&nbsp;a&nbsp;decision&nbsp;tree,&nbsp;their&nbsp;practical<br>
&nbsp;&nbsp;&nbsp;&nbsp;utility&nbsp;is&nbsp;best&nbsp;understood&nbsp;with&nbsp;an&nbsp;example&nbsp;that&nbsp;only&nbsp;involves&nbsp;symbolic<br>
&nbsp;&nbsp;&nbsp;&nbsp;features.&nbsp;&nbsp;However,&nbsp;as&nbsp;mentioned&nbsp;earlier,&nbsp;versions&nbsp;2.0&nbsp;and&nbsp;higher&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;module&nbsp;handle&nbsp;both&nbsp;symbolic&nbsp;and&nbsp;numeric&nbsp;features.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Consider&nbsp;the&nbsp;following&nbsp;scenario:&nbsp;Let's&nbsp;say&nbsp;you&nbsp;are&nbsp;running&nbsp;a&nbsp;small<br>
&nbsp;&nbsp;&nbsp;&nbsp;investment&nbsp;company&nbsp;that&nbsp;employs&nbsp;a&nbsp;team&nbsp;of&nbsp;stockbrokers&nbsp;who&nbsp;make<br>
&nbsp;&nbsp;&nbsp;&nbsp;buy/sell&nbsp;decisions&nbsp;for&nbsp;the&nbsp;customers&nbsp;of&nbsp;your&nbsp;company.&nbsp;&nbsp;Assume&nbsp;that&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;company&nbsp;has&nbsp;asked&nbsp;the&nbsp;traders&nbsp;to&nbsp;make&nbsp;each&nbsp;investment&nbsp;decision&nbsp;on&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;basis&nbsp;of&nbsp;the&nbsp;following&nbsp;five&nbsp;criteria:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;price_to_earnings_ratio&nbsp;&nbsp;&nbsp;(P_to_E)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;price_to_sales_ratio&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(P_to_S)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return_on_equity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(R_on_E)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;market_share&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(M_S)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentiment&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(S)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Since&nbsp;you&nbsp;are&nbsp;the&nbsp;boss,&nbsp;you&nbsp;keep&nbsp;track&nbsp;of&nbsp;the&nbsp;buy/sell&nbsp;decisions&nbsp;made<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;the&nbsp;individual&nbsp;traders.&nbsp;&nbsp;But&nbsp;one&nbsp;unfortunate&nbsp;day,&nbsp;all&nbsp;of&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;traders&nbsp;decide&nbsp;to&nbsp;quit&nbsp;because&nbsp;you&nbsp;did&nbsp;not&nbsp;pay&nbsp;them&nbsp;enough.&nbsp;&nbsp;So&nbsp;what<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;you&nbsp;to&nbsp;do?&nbsp;&nbsp;If&nbsp;you&nbsp;had&nbsp;a&nbsp;module&nbsp;like&nbsp;the&nbsp;one&nbsp;here,&nbsp;you&nbsp;could&nbsp;still<br>
&nbsp;&nbsp;&nbsp;&nbsp;run&nbsp;your&nbsp;company&nbsp;and&nbsp;do&nbsp;so&nbsp;in&nbsp;such&nbsp;a&nbsp;way&nbsp;that&nbsp;your&nbsp;company&nbsp;would,&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;average,&nbsp;perform&nbsp;better&nbsp;than&nbsp;any&nbsp;of&nbsp;the&nbsp;individual&nbsp;traders&nbsp;who<br>
&nbsp;&nbsp;&nbsp;&nbsp;worked&nbsp;for&nbsp;you&nbsp;previously.&nbsp;&nbsp;This&nbsp;is&nbsp;what&nbsp;you&nbsp;would&nbsp;need&nbsp;to&nbsp;do::&nbsp;You<br>
&nbsp;&nbsp;&nbsp;&nbsp;would&nbsp;pool&nbsp;together&nbsp;the&nbsp;individual&nbsp;trader&nbsp;buy/sell&nbsp;decisions&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;accumulated&nbsp;during&nbsp;the&nbsp;last&nbsp;one&nbsp;year.&nbsp;&nbsp;This&nbsp;pooled&nbsp;information&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;likely&nbsp;to&nbsp;look&nbsp;like:<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;example&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buy/sell&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P_to_E&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P_to_S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;R_on_E&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;M_S&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;S<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;====================================================================<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;example_1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;high&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;medium&nbsp;&nbsp;&nbsp;&nbsp;low&nbsp;&nbsp;&nbsp;&nbsp;high<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;example_2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;medium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;medium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low&nbsp;&nbsp;&nbsp;&nbsp;medium<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;example_3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sell&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;medium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;high&nbsp;&nbsp;&nbsp;low<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;data&nbsp;would&nbsp;constitute&nbsp;your&nbsp;training&nbsp;file.&nbsp;Assuming&nbsp;that&nbsp;this&nbsp;training<br>
&nbsp;&nbsp;&nbsp;&nbsp;file&nbsp;is&nbsp;called&nbsp;'training.dat',&nbsp;you&nbsp;would&nbsp;need&nbsp;to&nbsp;feed&nbsp;this&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;into&nbsp;the&nbsp;module&nbsp;by&nbsp;calling:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt&nbsp;=&nbsp;<a href="#DecisionTree">DecisionTree</a>(&nbsp;training_datafile&nbsp;=&nbsp;"training.dat"&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.get_training_data()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_first_order_probabilities_for_numeric_features()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_class_priors()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Subsequently,&nbsp;you&nbsp;would&nbsp;construct&nbsp;a&nbsp;decision&nbsp;tree&nbsp;by&nbsp;calling:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root_node&nbsp;=&nbsp;dt.construct_decision_tree_classifier()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Now&nbsp;you&nbsp;and&nbsp;your&nbsp;company&nbsp;(with&nbsp;practically&nbsp;no&nbsp;employees)&nbsp;are&nbsp;ready&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;service&nbsp;the&nbsp;customers&nbsp;again.&nbsp;Suppose&nbsp;your&nbsp;computer&nbsp;needs&nbsp;to&nbsp;make&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;buy/sell&nbsp;decision&nbsp;about&nbsp;an&nbsp;investment&nbsp;prospect&nbsp;that&nbsp;is&nbsp;best&nbsp;described<br>
&nbsp;&nbsp;&nbsp;&nbsp;by:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;price_to_earnings_ratio&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;low<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;price_to_sales_ratio&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;very_low<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return_on_equity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;none<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;market_share&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;medium&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentiment&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;low<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;All&nbsp;that&nbsp;your&nbsp;computer&nbsp;would&nbsp;need&nbsp;to&nbsp;do&nbsp;would&nbsp;be&nbsp;to&nbsp;construct&nbsp;a&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;vector&nbsp;like<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_case&nbsp;=&nbsp;[&nbsp;'P_to_E=low',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'P_to_S=very_low',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'R_on_E=none',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'M_S=medium',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'S=low'&nbsp;&nbsp;]<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;call&nbsp;the&nbsp;decision&nbsp;tree&nbsp;classifier&nbsp;you&nbsp;just&nbsp;constructed&nbsp;by<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;=&nbsp;dt.classify(root_node,&nbsp;test_case)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;"Classification:&nbsp;",&nbsp;classification<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;answer&nbsp;returned&nbsp;will&nbsp;be&nbsp;'buy'&nbsp;and&nbsp;'sell',&nbsp;along&nbsp;with&nbsp;the&nbsp;associated<br>
&nbsp;&nbsp;&nbsp;&nbsp;probabilities.&nbsp;&nbsp;So&nbsp;if&nbsp;the&nbsp;probability&nbsp;of&nbsp;'buy'&nbsp;is&nbsp;considerably&nbsp;greater<br>
&nbsp;&nbsp;&nbsp;&nbsp;than&nbsp;the&nbsp;probability&nbsp;of&nbsp;'sell',&nbsp;that's&nbsp;what&nbsp;you&nbsp;should&nbsp;instruct&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;computer&nbsp;to&nbsp;do.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;chances&nbsp;are&nbsp;that,&nbsp;on&nbsp;the&nbsp;average,&nbsp;this&nbsp;approach&nbsp;would&nbsp;beat&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;performance&nbsp;of&nbsp;any&nbsp;of&nbsp;your&nbsp;individual&nbsp;traders&nbsp;who&nbsp;worked&nbsp;for&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;previously&nbsp;since&nbsp;the&nbsp;buy/sell&nbsp;decisions&nbsp;made&nbsp;by&nbsp;the&nbsp;computer&nbsp;would&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;based&nbsp;on&nbsp;the&nbsp;collective&nbsp;wisdom&nbsp;of&nbsp;all&nbsp;your&nbsp;previous&nbsp;traders.<br>
&nbsp;&nbsp;&nbsp;&nbsp;DISCLAIMER:&nbsp;There&nbsp;is&nbsp;obviously&nbsp;a&nbsp;lot&nbsp;more&nbsp;to&nbsp;good&nbsp;investing&nbsp;than&nbsp;what<br>
&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;captured&nbsp;by&nbsp;the&nbsp;silly&nbsp;little&nbsp;example&nbsp;here.&nbsp;However,&nbsp;it&nbsp;does<br>
&nbsp;&nbsp;&nbsp;&nbsp;convey&nbsp;the&nbsp;sense&nbsp;in&nbsp;which&nbsp;the&nbsp;current&nbsp;module&nbsp;can&nbsp;be&nbsp;used.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">SYMBOLIC&nbsp;FEATURES&nbsp;VERSUS&nbsp;NUMERIC&nbsp;FEATURES<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;feature&nbsp;is&nbsp;symbolic&nbsp;when&nbsp;its&nbsp;values&nbsp;are&nbsp;compared&nbsp;using&nbsp;string<br>
&nbsp;&nbsp;&nbsp;&nbsp;comparison&nbsp;operators.&nbsp;&nbsp;By&nbsp;the&nbsp;same&nbsp;token,&nbsp;a&nbsp;feature&nbsp;is&nbsp;numeric&nbsp;when&nbsp;its<br>
&nbsp;&nbsp;&nbsp;&nbsp;values&nbsp;are&nbsp;compared&nbsp;using&nbsp;numeric&nbsp;comparison&nbsp;operators.&nbsp;&nbsp;Having&nbsp;said<br>
&nbsp;&nbsp;&nbsp;&nbsp;that,&nbsp;features&nbsp;that&nbsp;take&nbsp;only&nbsp;a&nbsp;small&nbsp;number&nbsp;of&nbsp;numeric&nbsp;values&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;training&nbsp;data&nbsp;can&nbsp;be&nbsp;treated&nbsp;symbolically&nbsp;provided&nbsp;you&nbsp;are&nbsp;careful<br>
&nbsp;&nbsp;&nbsp;&nbsp;about&nbsp;handling&nbsp;their&nbsp;values&nbsp;in&nbsp;the&nbsp;test&nbsp;data.&nbsp;&nbsp;At&nbsp;the&nbsp;least,&nbsp;you&nbsp;have&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;set&nbsp;the&nbsp;test&nbsp;data&nbsp;value&nbsp;for&nbsp;such&nbsp;a&nbsp;feature&nbsp;to&nbsp;its&nbsp;closest&nbsp;value&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data.&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;constructor&nbsp;parameter&nbsp;symbolic_to_numeric_cardinality_threshold<br>
&nbsp;&nbsp;&nbsp;&nbsp;let's&nbsp;you&nbsp;tell&nbsp;the&nbsp;module&nbsp;when&nbsp;to&nbsp;consider&nbsp;an&nbsp;otherwise&nbsp;numeric&nbsp;feature<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolically.&nbsp;Suppose&nbsp;you&nbsp;set&nbsp;this&nbsp;parameter&nbsp;to&nbsp;10,&nbsp;that&nbsp;means&nbsp;that&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;numeric&nbsp;looking&nbsp;features&nbsp;that&nbsp;take&nbsp;10&nbsp;or&nbsp;fewer&nbsp;different&nbsp;values&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;datafile&nbsp;will&nbsp;be&nbsp;considered&nbsp;to&nbsp;be&nbsp;symbolic&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;See&nbsp;the&nbsp;tutorial&nbsp;at<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://engineering.purdue.edu/kak/Tutorials/DecisionTreeClassifiers.pdf">https://engineering.purdue.edu/kak/Tutorials/DecisionTreeClassifiers.pdf</a><br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;further&nbsp;information&nbsp;on&nbsp;the&nbsp;implementation&nbsp;issues&nbsp;related&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolic&nbsp;and&nbsp;numeric&nbsp;features.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">TESTING&nbsp;THE&nbsp;QUALITY&nbsp;OF&nbsp;YOUR&nbsp;TRAINING&nbsp;DATA:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Version&nbsp;2.2&nbsp;includes&nbsp;a&nbsp;new&nbsp;class&nbsp;named&nbsp;<a href="#EvalTrainingData">EvalTrainingData</a>,&nbsp;derived&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;main&nbsp;class&nbsp;<a href="#DecisionTree">DecisionTree</a>,&nbsp;that&nbsp;runs&nbsp;a&nbsp;10-fold&nbsp;cross-validation&nbsp;test<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;your&nbsp;training&nbsp;data&nbsp;to&nbsp;test&nbsp;its&nbsp;ability&nbsp;to&nbsp;discriminate&nbsp;between&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;mentioned&nbsp;in&nbsp;the&nbsp;training&nbsp;file.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;10-fold&nbsp;cross-validation&nbsp;test&nbsp;divides&nbsp;all&nbsp;of&nbsp;the&nbsp;training&nbsp;data&nbsp;into<br>
&nbsp;&nbsp;&nbsp;&nbsp;ten&nbsp;parts,&nbsp;with&nbsp;nine&nbsp;parts&nbsp;used&nbsp;for&nbsp;training&nbsp;a&nbsp;decision&nbsp;tree&nbsp;and&nbsp;one<br>
&nbsp;&nbsp;&nbsp;&nbsp;part&nbsp;used&nbsp;for&nbsp;testing&nbsp;its&nbsp;ability&nbsp;to&nbsp;classify&nbsp;correctly.&nbsp;This&nbsp;selection<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;nine&nbsp;parts&nbsp;for&nbsp;training&nbsp;and&nbsp;one&nbsp;part&nbsp;for&nbsp;testing&nbsp;is&nbsp;carried&nbsp;out&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;of&nbsp;the&nbsp;ten&nbsp;different&nbsp;possible&nbsp;ways.&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;following&nbsp;code&nbsp;fragment&nbsp;illustrates&nbsp;how&nbsp;you&nbsp;invoke&nbsp;the&nbsp;testing<br>
&nbsp;&nbsp;&nbsp;&nbsp;function&nbsp;of&nbsp;the&nbsp;<a href="#EvalTrainingData">EvalTrainingData</a>&nbsp;class:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_datafile&nbsp;=&nbsp;"training3.csv"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;eval_data&nbsp;=&nbsp;<a href="#DecisionTree">DecisionTree</a>.<a href="#EvalTrainingData">EvalTrainingData</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_datafile&nbsp;=&nbsp;training_datafile,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;csv_class_column_index&nbsp;=&nbsp;1,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;csv_columns_for_features&nbsp;=&nbsp;[2,3],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entropy_threshold&nbsp;=&nbsp;0.01,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_depth_desired&nbsp;=&nbsp;3,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;symbolic_to_numeric_cardinality_threshold&nbsp;=&nbsp;10,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;eval_data.get_training_data()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;eval_data.evaluate_training_data()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;last&nbsp;statement&nbsp;above&nbsp;prints&nbsp;out&nbsp;a&nbsp;Confusion&nbsp;Matrix&nbsp;and&nbsp;the&nbsp;value&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;Training&nbsp;Data&nbsp;Quality&nbsp;Index&nbsp;on&nbsp;a&nbsp;scale&nbsp;of&nbsp;100,&nbsp;with&nbsp;100&nbsp;designating<br>
&nbsp;&nbsp;&nbsp;&nbsp;perfect&nbsp;training&nbsp;data.&nbsp;&nbsp;The&nbsp;Confusion&nbsp;Matrix&nbsp;shows&nbsp;how&nbsp;the&nbsp;different<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;were&nbsp;mis-identified&nbsp;in&nbsp;the&nbsp;10-fold&nbsp;cross-validation&nbsp;test.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;testing&nbsp;functionality&nbsp;can&nbsp;also&nbsp;be&nbsp;used&nbsp;to&nbsp;find&nbsp;the&nbsp;best&nbsp;values&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;use&nbsp;for&nbsp;the&nbsp;constructor&nbsp;parameters&nbsp;entropy_threshold,<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth_desired,&nbsp;and&nbsp;symbolic_to_numeric_cardinality_threshold.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;following&nbsp;two&nbsp;scripts&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;illustrate&nbsp;the&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;<a href="#EvalTrainingData">EvalTrainingData</a>&nbsp;class&nbsp;for&nbsp;testing&nbsp;the&nbsp;quality&nbsp;of&nbsp;your&nbsp;data:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;evaluate_training_data1.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;evaluate_training_data2.py<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">HOW&nbsp;TO&nbsp;MAKE&nbsp;THE&nbsp;BEST&nbsp;CHOICES&nbsp;FOR&nbsp;THE&nbsp;CONSTRUCTOR<br>PARAMETERS:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Assuming&nbsp;your&nbsp;training&nbsp;data&nbsp;is&nbsp;good,&nbsp;the&nbsp;quality&nbsp;of&nbsp;the&nbsp;results&nbsp;you&nbsp;get<br>
&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;a&nbsp;decision&nbsp;tree&nbsp;would&nbsp;depend&nbsp;on&nbsp;the&nbsp;choices&nbsp;you&nbsp;make&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;parameters&nbsp;entropy_threshold,&nbsp;max_depth_desired,&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolic_to_numeric_cardinality_threshold.&nbsp;&nbsp;You&nbsp;can&nbsp;optimize&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;choices&nbsp;for&nbsp;these&nbsp;parameters&nbsp;by&nbsp;running&nbsp;the&nbsp;10-fold&nbsp;cross-validation<br>
&nbsp;&nbsp;&nbsp;&nbsp;test&nbsp;that&nbsp;is&nbsp;made&nbsp;available&nbsp;in&nbsp;Version&nbsp;2.2&nbsp;through&nbsp;the&nbsp;new&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#EvalTrainingData">EvalTrainingData</a>&nbsp;that&nbsp;is&nbsp;included&nbsp;in&nbsp;the&nbsp;module&nbsp;file.&nbsp;&nbsp;A&nbsp;description&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;how&nbsp;to&nbsp;run&nbsp;this&nbsp;test&nbsp;is&nbsp;in&nbsp;the&nbsp;section&nbsp;titled&nbsp;"TESTING&nbsp;THE&nbsp;QUALITY&nbsp;OF<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOUR&nbsp;TRAINING&nbsp;DATA"&nbsp;of&nbsp;this&nbsp;document.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
<font size=+2 color="red">METHODS:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;module&nbsp;provides&nbsp;the&nbsp;following&nbsp;methods&nbsp;for&nbsp;constructing&nbsp;a&nbsp;decision<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree&nbsp;from&nbsp;training&nbsp;data&nbsp;in&nbsp;a&nbsp;disk&nbsp;file,&nbsp;and&nbsp;for&nbsp;data&nbsp;classification&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Constructing&nbsp;a&nbsp;decision&nbsp;tree:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt&nbsp;=&nbsp;<a href="#DecisionTree">DecisionTree</a>(&nbsp;training_datafile&nbsp;=&nbsp;training_datafile,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;csv_class_column_index&nbsp;=&nbsp;2,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;csv_columns_for_features&nbsp;=&nbsp;[3,4,5,6,7,8],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entropy_threshold&nbsp;=&nbsp;0.01,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_depth_desired&nbsp;=&nbsp;8,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;symbolic_to_numeric_cardinality_threshold&nbsp;=&nbsp;10,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;yields&nbsp;a&nbsp;new&nbsp;instance&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;class.&nbsp;&nbsp;For&nbsp;this&nbsp;call&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;make&nbsp;sense,&nbsp;the&nbsp;training&nbsp;data&nbsp;in&nbsp;the&nbsp;training&nbsp;datafile&nbsp;must&nbsp;be&nbsp;conform<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;certain&nbsp;format.&nbsp;&nbsp;For&nbsp;example,&nbsp;the&nbsp;first&nbsp;row&nbsp;must&nbsp;name&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;features.&nbsp;&nbsp;It&nbsp;must&nbsp;begin&nbsp;with&nbsp;the&nbsp;empty&nbsp;string&nbsp;`""'&nbsp;as&nbsp;shown&nbsp;by&nbsp;the&nbsp;CSV<br>
&nbsp;&nbsp;&nbsp;&nbsp;files&nbsp;in&nbsp;the&nbsp;Examples&nbsp;subdirectory.&nbsp;&nbsp;The&nbsp;first&nbsp;column&nbsp;for&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;subsequent&nbsp;rows&nbsp;must&nbsp;carry&nbsp;a&nbsp;unique&nbsp;integer&nbsp;identifier&nbsp;for&nbsp;each&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;record.&nbsp;&nbsp;When&nbsp;your&nbsp;features&nbsp;are&nbsp;purely&nbsp;symbolic,&nbsp;you&nbsp;are&nbsp;also&nbsp;allowed<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;use&nbsp;the&nbsp;`.dat'&nbsp;files&nbsp;that&nbsp;were&nbsp;used&nbsp;in&nbsp;the&nbsp;previous&nbsp;versions&nbsp;of&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;module.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;constructor&nbsp;option&nbsp;csv_class_column_index&nbsp;supplies&nbsp;to&nbsp;the&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;zero-based&nbsp;index&nbsp;of&nbsp;the&nbsp;column&nbsp;that&nbsp;contains&nbsp;the&nbsp;class&nbsp;label&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data&nbsp;records.&nbsp;In&nbsp;the&nbsp;example&nbsp;shown&nbsp;above,&nbsp;the&nbsp;class&nbsp;labels&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;third&nbsp;column.&nbsp;&nbsp;The&nbsp;option&nbsp;csv_columns_for_features&nbsp;tells&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;module&nbsp;which&nbsp;of&nbsp;the&nbsp;features&nbsp;are&nbsp;supposed&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;decision&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;construction.&nbsp;&nbsp;The&nbsp;constructor&nbsp;option&nbsp;max_depth_desired&nbsp;sets&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.&nbsp;The&nbsp;parameter&nbsp;entropy_threshold<br>
&nbsp;&nbsp;&nbsp;&nbsp;sets&nbsp;the&nbsp;granularity&nbsp;with&nbsp;which&nbsp;the&nbsp;entropies&nbsp;are&nbsp;sampled.&nbsp;&nbsp;The<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;symbolic_to_numeric_cardinality_threshold&nbsp;allows&nbsp;the&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;treat&nbsp;an&nbsp;otherwise&nbsp;numeric&nbsp;feature&nbsp;symbolically&nbsp;if&nbsp;it&nbsp;only&nbsp;takes&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;small&nbsp;number&nbsp;of&nbsp;different&nbsp;values&nbsp;in&nbsp;the&nbsp;training&nbsp;data&nbsp;file.&nbsp;&nbsp;For&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;call&nbsp;shown&nbsp;above,&nbsp;if&nbsp;a&nbsp;feature&nbsp;takes&nbsp;on&nbsp;only&nbsp;10&nbsp;or&nbsp;fewer<br>
&nbsp;&nbsp;&nbsp;&nbsp;different&nbsp;values&nbsp;in&nbsp;the&nbsp;training&nbsp;data&nbsp;file,&nbsp;it&nbsp;will&nbsp;be&nbsp;treated&nbsp;like&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolic&nbsp;feature.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">The&nbsp;constructor&nbsp;parameters:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;training_datafile:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;parameter&nbsp;supplies&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;file&nbsp;that&nbsp;contains&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data.&nbsp;&nbsp;This&nbsp;must&nbsp;be&nbsp;a&nbsp;CSV&nbsp;file&nbsp;if&nbsp;your&nbsp;training&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;includes&nbsp;both&nbsp;numeric&nbsp;and&nbsp;symbolic&nbsp;features.&nbsp;&nbsp;If&nbsp;your&nbsp;data&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purely&nbsp;symbolic,&nbsp;you&nbsp;can&nbsp;use&nbsp;the&nbsp;old-style&nbsp;`.dat'&nbsp;file.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;csv_class_column_index:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;using&nbsp;a&nbsp;CSV&nbsp;file&nbsp;for&nbsp;your&nbsp;training&nbsp;data,&nbsp;this&nbsp;parameter<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;supplies&nbsp;the&nbsp;zero-based&nbsp;column&nbsp;index&nbsp;for&nbsp;the&nbsp;column&nbsp;that&nbsp;contains<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;class&nbsp;label&nbsp;for&nbsp;each&nbsp;data&nbsp;record&nbsp;in&nbsp;the&nbsp;training&nbsp;file.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;csv_columns_for_features:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;using&nbsp;a&nbsp;CSV&nbsp;file&nbsp;for&nbsp;your&nbsp;training&nbsp;data,&nbsp;this&nbsp;parameter<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;supplies&nbsp;a&nbsp;list&nbsp;of&nbsp;columns&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;features&nbsp;you&nbsp;wish<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;use&nbsp;for&nbsp;decision&nbsp;tree&nbsp;construction.&nbsp;&nbsp;Each&nbsp;column&nbsp;is&nbsp;specified&nbsp;by<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;its&nbsp;zero-based&nbsp;index.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;entropy_threshold:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;parameter&nbsp;sets&nbsp;the&nbsp;granularity&nbsp;with&nbsp;which&nbsp;the&nbsp;entropies&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sampled&nbsp;by&nbsp;the&nbsp;module.&nbsp;&nbsp;For&nbsp;example,&nbsp;a&nbsp;feature&nbsp;test&nbsp;at&nbsp;a&nbsp;node&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;decision&nbsp;tree&nbsp;is&nbsp;acceptable&nbsp;if&nbsp;the&nbsp;entropy&nbsp;gain&nbsp;achieved&nbsp;by&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test&nbsp;exceeds&nbsp;this&nbsp;threshold.&nbsp;&nbsp;The&nbsp;larger&nbsp;the&nbsp;value&nbsp;you&nbsp;choose&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;parameter,&nbsp;the&nbsp;smaller&nbsp;the&nbsp;tree.&nbsp;&nbsp;Its&nbsp;default&nbsp;value&nbsp;is&nbsp;0.001.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_depth_desired:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;parameter&nbsp;sets&nbsp;the&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree.&nbsp;&nbsp;For<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;obvious&nbsp;reasons,&nbsp;the&nbsp;smaller&nbsp;the&nbsp;value&nbsp;you&nbsp;choose&nbsp;for&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter,&nbsp;the&nbsp;smaller&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;symbolic_to_numeric_cardinality_threshold:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;parameter&nbsp;allows&nbsp;the&nbsp;module&nbsp;to&nbsp;treat&nbsp;an&nbsp;otherwise&nbsp;numeric<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;feature&nbsp;symbolically&nbsp;if&nbsp;the&nbsp;number&nbsp;of&nbsp;different&nbsp;values&nbsp;the&nbsp;feature<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;takes&nbsp;in&nbsp;the&nbsp;training&nbsp;data&nbsp;file&nbsp;does&nbsp;not&nbsp;exceed&nbsp;the&nbsp;value&nbsp;of&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;can&nbsp;choose&nbsp;the&nbsp;best&nbsp;values&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;last&nbsp;three&nbsp;constructor<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameters&nbsp;by&nbsp;running&nbsp;a&nbsp;10-fold&nbsp;cross-validation&nbsp;test&nbsp;on&nbsp;your&nbsp;training<br>
&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;through&nbsp;the&nbsp;embedded&nbsp;class&nbsp;<a href="#EvalTrainingData">EvalTrainingData</a>&nbsp;that&nbsp;comes&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;Version&nbsp;2.2&nbsp;of&nbsp;this&nbsp;module.&nbsp;&nbsp;See&nbsp;the&nbsp;section&nbsp;"TESTING&nbsp;THE&nbsp;QUALITY&nbsp;OF<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOUR&nbsp;TRAINING&nbsp;DATA"&nbsp;of&nbsp;this&nbsp;document&nbsp;page.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Reading&nbsp;in&nbsp;the&nbsp;training&nbsp;data:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;After&nbsp;you&nbsp;have&nbsp;constructed&nbsp;a&nbsp;new&nbsp;instance&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;class,<br>
&nbsp;&nbsp;&nbsp;&nbsp;you&nbsp;must&nbsp;now&nbsp;read&nbsp;in&nbsp;the&nbsp;training&nbsp;data&nbsp;that&nbsp;is&nbsp;contained&nbsp;in&nbsp;the&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;named&nbsp;above.&nbsp;&nbsp;This&nbsp;you&nbsp;do&nbsp;by:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.get_training_data()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;IMPORTANT:&nbsp;The&nbsp;training&nbsp;data&nbsp;file&nbsp;must&nbsp;be&nbsp;in&nbsp;a&nbsp;format&nbsp;that&nbsp;makes&nbsp;sense<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;decision&nbsp;tree&nbsp;constructor.&nbsp;&nbsp;If&nbsp;you&nbsp;use&nbsp;numeric&nbsp;features,&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;must&nbsp;use&nbsp;a&nbsp;CSV&nbsp;file&nbsp;for&nbsp;supplying&nbsp;the&nbsp;training&nbsp;data.&nbsp;&nbsp;The&nbsp;first&nbsp;row&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;such&nbsp;a&nbsp;file&nbsp;must&nbsp;name&nbsp;the&nbsp;features&nbsp;and&nbsp;it&nbsp;must&nbsp;begin&nbsp;with&nbsp;the&nbsp;empty<br>
&nbsp;&nbsp;&nbsp;&nbsp;string&nbsp;`""'&nbsp;as&nbsp;shown&nbsp;in&nbsp;the&nbsp;`stage3cancer.csv'&nbsp;file&nbsp;in&nbsp;the&nbsp;Examples<br>
&nbsp;&nbsp;&nbsp;&nbsp;subdirectory.&nbsp;&nbsp;The&nbsp;first&nbsp;column&nbsp;for&nbsp;all&nbsp;subsequent&nbsp;rows&nbsp;must&nbsp;carry&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;unique&nbsp;integer&nbsp;identifier&nbsp;for&nbsp;each&nbsp;training&nbsp;record.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Initializing&nbsp;the&nbsp;probability&nbsp;cache:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;After&nbsp;a&nbsp;call&nbsp;to&nbsp;the&nbsp;constructor&nbsp;and&nbsp;the&nbsp;get_training_data()&nbsp;method,&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;must&nbsp;call&nbsp;the&nbsp;following&nbsp;methods&nbsp;for&nbsp;initializing&nbsp;the&nbsp;probabilities:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_first_order_probabilities()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.calculate_class_priors()<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Displaying&nbsp;the&nbsp;training&nbsp;data:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;wish&nbsp;to&nbsp;see&nbsp;the&nbsp;training&nbsp;data&nbsp;that&nbsp;was&nbsp;just&nbsp;digested&nbsp;by&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;module,&nbsp;call<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.show_training_data()&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Constructing&nbsp;a&nbsp;decision-tree&nbsp;classifier:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;After&nbsp;the&nbsp;training&nbsp;data&nbsp;is&nbsp;ingested,&nbsp;it&nbsp;is&nbsp;time&nbsp;to&nbsp;construct&nbsp;a&nbsp;decision<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree&nbsp;classifier.&nbsp;&nbsp;This&nbsp;you&nbsp;do&nbsp;by<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root_node&nbsp;=&nbsp;dt.construct_decision_tree_classifier()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;call&nbsp;returns&nbsp;an&nbsp;instance&nbsp;of&nbsp;type&nbsp;<a href="#DTNode">DTNode</a>.&nbsp;&nbsp;The&nbsp;<a href="#DTNode">DTNode</a>&nbsp;class&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;defined&nbsp;within&nbsp;the&nbsp;main&nbsp;package&nbsp;file,&nbsp;at&nbsp;its&nbsp;end.&nbsp;&nbsp;So,&nbsp;don't&nbsp;forget,<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;root_node&nbsp;in&nbsp;the&nbsp;above&nbsp;example&nbsp;call&nbsp;will&nbsp;be&nbsp;instantiated&nbsp;to&nbsp;an<br>
&nbsp;&nbsp;&nbsp;&nbsp;instance&nbsp;of&nbsp;type&nbsp;<a href="#DTNode">DTNode</a>.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Displaying&nbsp;the&nbsp;decision&nbsp;tree:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;display&nbsp;a&nbsp;decision&nbsp;tree&nbsp;by&nbsp;calling<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root_node.display_decision_tree("&nbsp;&nbsp;&nbsp;")<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;displays&nbsp;the&nbsp;decision&nbsp;tree&nbsp;in&nbsp;your&nbsp;terminal&nbsp;window&nbsp;by&nbsp;using&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;recursively&nbsp;determined&nbsp;offset&nbsp;for&nbsp;each&nbsp;node&nbsp;as&nbsp;the&nbsp;display&nbsp;routine<br>
&nbsp;&nbsp;&nbsp;&nbsp;descends&nbsp;down&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;I&nbsp;have&nbsp;intentionally&nbsp;left&nbsp;the&nbsp;syntax&nbsp;fragment&nbsp;root_node&nbsp;in&nbsp;the&nbsp;above<br>
&nbsp;&nbsp;&nbsp;&nbsp;call&nbsp;to&nbsp;remind&nbsp;the&nbsp;reader&nbsp;that&nbsp;display_decision_tree()&nbsp;is&nbsp;NOT&nbsp;called&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;instance&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;we&nbsp;constructed&nbsp;earlier,&nbsp;but&nbsp;on&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;Node&nbsp;instance&nbsp;returned&nbsp;by&nbsp;the&nbsp;call&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;construct_decision_tree_classifier().<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Classifying&nbsp;new&nbsp;data:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;classify&nbsp;new&nbsp;data&nbsp;by&nbsp;first&nbsp;constructing&nbsp;a&nbsp;new&nbsp;data&nbsp;vector:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_sample&nbsp;&nbsp;=&nbsp;['g2&nbsp;=&nbsp;4.2',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'grade&nbsp;=&nbsp;2.3',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'gleason&nbsp;=&nbsp;4',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'eet&nbsp;=&nbsp;1.7',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'age&nbsp;=&nbsp;55.0',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'ploidy&nbsp;=&nbsp;diploid']<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;calling&nbsp;the&nbsp;classify()&nbsp;method&nbsp;as&nbsp;follows:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;=&nbsp;dt.classify(root_node,&nbsp;test_sample)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;where,&nbsp;again,&nbsp;root_node&nbsp;is&nbsp;an&nbsp;instance&nbsp;of&nbsp;type&nbsp;Node&nbsp;that&nbsp;was&nbsp;returned<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;calling&nbsp;construct_decision_tree_classifier().&nbsp;&nbsp;The&nbsp;variable<br>
&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;is&nbsp;a&nbsp;dictionary&nbsp;whose&nbsp;keys&nbsp;are&nbsp;the&nbsp;class&nbsp;labels&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;whose&nbsp;values&nbsp;the&nbsp;associated&nbsp;probabilities.&nbsp;&nbsp;You&nbsp;can&nbsp;print&nbsp;it&nbsp;out&nbsp;by<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print&nbsp;"Classification:&nbsp;",&nbsp;classification<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Displaying&nbsp;the&nbsp;number&nbsp;of&nbsp;nodes&nbsp;created:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;can&nbsp;print&nbsp;out&nbsp;the&nbsp;number&nbsp;of&nbsp;nodes&nbsp;in&nbsp;a&nbsp;decision&nbsp;tree&nbsp;by&nbsp;calling<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root_node.how_many_nodes()<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Using&nbsp;the&nbsp;decision&nbsp;tree&nbsp;interactively:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Starting&nbsp;with&nbsp;Version&nbsp;1.6&nbsp;of&nbsp;the&nbsp;module,&nbsp;you&nbsp;can&nbsp;use&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;classifier&nbsp;in&nbsp;an&nbsp;interactive&nbsp;mode.&nbsp;&nbsp;In&nbsp;this&nbsp;mode,&nbsp;after&nbsp;you&nbsp;have<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructed&nbsp;the&nbsp;decision&nbsp;tree,&nbsp;the&nbsp;user&nbsp;is&nbsp;prompted&nbsp;for&nbsp;answers&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;questions&nbsp;regarding&nbsp;the&nbsp;feature&nbsp;tests&nbsp;at&nbsp;the&nbsp;nodes&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Depending&nbsp;on&nbsp;the&nbsp;answer&nbsp;supplied&nbsp;by&nbsp;the&nbsp;user&nbsp;at&nbsp;a&nbsp;node,&nbsp;the&nbsp;classifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;takes&nbsp;a&nbsp;path&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;answer&nbsp;to&nbsp;descend&nbsp;down&nbsp;the&nbsp;tree&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;next&nbsp;node,&nbsp;and&nbsp;so&nbsp;on.&nbsp;&nbsp;The&nbsp;following&nbsp;method&nbsp;makes&nbsp;this&nbsp;mode<br>
&nbsp;&nbsp;&nbsp;&nbsp;possible.&nbsp;&nbsp;Obviously,&nbsp;you&nbsp;can&nbsp;call&nbsp;this&nbsp;method&nbsp;only&nbsp;after&nbsp;you&nbsp;have<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructed&nbsp;the&nbsp;decision&nbsp;tree.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dt.classify_by_asking_questions(root_node)<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Generating&nbsp;synthetic&nbsp;training&nbsp;data:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;To&nbsp;generate&nbsp;synthetic&nbsp;training&nbsp;data,&nbsp;you&nbsp;first&nbsp;construct&nbsp;an&nbsp;instance&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;class&nbsp;TrainingDataGenerator&nbsp;that&nbsp;is&nbsp;incorporated&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module.&nbsp;&nbsp;A&nbsp;call&nbsp;to&nbsp;the&nbsp;constructor&nbsp;of&nbsp;this&nbsp;class&nbsp;will&nbsp;look<br>
&nbsp;&nbsp;&nbsp;&nbsp;like:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter_file&nbsp;=&nbsp;"param_numeric.txt"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_csv_file&nbsp;=&nbsp;"training.csv";<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen&nbsp;=&nbsp;<a href="#TrainingDataGeneratorNumeric">TrainingDataGeneratorNumeric</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_csv_file&nbsp;&nbsp;&nbsp;=&nbsp;output_csv_file,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter_file&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;parameter_file,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number_of_samples_per_class&nbsp;=&nbsp;some_number,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen.read_parameter_file_numeric()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen.gen_numeric_training_data_and_write_to_csv()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;training&nbsp;data&nbsp;that&nbsp;is&nbsp;generated&nbsp;is&nbsp;according&nbsp;to&nbsp;the&nbsp;specifications<br>
&nbsp;&nbsp;&nbsp;&nbsp;described&nbsp;in&nbsp;the&nbsp;parameter&nbsp;file.&nbsp;&nbsp;The&nbsp;structure&nbsp;of&nbsp;this&nbsp;file&nbsp;must&nbsp;be&nbsp;as<br>
&nbsp;&nbsp;&nbsp;&nbsp;shown&nbsp;in&nbsp;the&nbsp;file&nbsp;`param_numeric.txt'&nbsp;for&nbsp;the&nbsp;numeric&nbsp;training&nbsp;data&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;as&nbsp;shown&nbsp;in&nbsp;`param_symbolic.txt'&nbsp;for&nbsp;the&nbsp;case&nbsp;of&nbsp;symbolic&nbsp;training<br>
&nbsp;&nbsp;&nbsp;&nbsp;data.&nbsp;&nbsp;Both&nbsp;these&nbsp;example&nbsp;parameter&nbsp;files&nbsp;are&nbsp;in&nbsp;the&nbsp;'Examples'<br>
&nbsp;&nbsp;&nbsp;&nbsp;subdirectory.&nbsp;&nbsp;The&nbsp;parameter&nbsp;file&nbsp;names&nbsp;the&nbsp;classes,&nbsp;the&nbsp;features&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;classes,&nbsp;and&nbsp;the&nbsp;possible&nbsp;values&nbsp;for&nbsp;the&nbsp;features.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;want&nbsp;to&nbsp;generate&nbsp;purely&nbsp;symbolic&nbsp;training&nbsp;data,&nbsp;here&nbsp;is&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;call&nbsp;to&nbsp;make:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter_file&nbsp;=&nbsp;"param_symbolic.txt"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_data_file&nbsp;=&nbsp;"training.dat";<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen&nbsp;=&nbsp;<a href="#TrainingDataGeneratorSymbolic">TrainingDataGeneratorSymbolic</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_datafile&nbsp;&nbsp;&nbsp;=&nbsp;output_data_file,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter_file&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;parameter_file,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;write_to_file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;1,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number_of_training_samples&nbsp;=&nbsp;some_number,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen.read_parameter_file_symbolic()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen.gen_symbolic_training_data()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data_gen.write_training_data_to_file()<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">Generating&nbsp;synthetic&nbsp;test&nbsp;data:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;To&nbsp;generate&nbsp;synthetic&nbsp;test&nbsp;data,&nbsp;you&nbsp;first&nbsp;construct&nbsp;an&nbsp;instance&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;<a href="#TestDataGeneratorSymbolic">TestDataGeneratorSymbolic</a>&nbsp;that&nbsp;is&nbsp;incorporated&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module.&nbsp;&nbsp;A&nbsp;call&nbsp;to&nbsp;the&nbsp;constructor&nbsp;of&nbsp;this&nbsp;class&nbsp;will&nbsp;look<br>
&nbsp;&nbsp;&nbsp;&nbsp;like:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_data_gen&nbsp;=&nbsp;<a href="#TestDataGeneratorSymbolic">TestDataGeneratorSymbolic</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_test_datafile&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;an_output_data_file,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_class_labels_file&nbsp;=&nbsp;a_file_for_class_labels,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter_file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;a_parameter_file,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;write_to_file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;1,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number_of_test_samples&nbsp;=&nbsp;some_number,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;main&nbsp;difference&nbsp;between&nbsp;the&nbsp;training&nbsp;data&nbsp;and&nbsp;the&nbsp;test&nbsp;data&nbsp;is&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;class&nbsp;labels&nbsp;are&nbsp;NOT&nbsp;mentioned&nbsp;in&nbsp;the&nbsp;latter.&nbsp;&nbsp;Instead,&nbsp;the&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels&nbsp;are&nbsp;placed&nbsp;in&nbsp;a&nbsp;separate&nbsp;file&nbsp;whose&nbsp;name&nbsp;is&nbsp;supplied&nbsp;through&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;option&nbsp;`output_class_labels_file'&nbsp;shown&nbsp;above.&nbsp;&nbsp;The&nbsp;test<br>
&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;that&nbsp;is&nbsp;generated&nbsp;is&nbsp;according&nbsp;to&nbsp;the&nbsp;specifications&nbsp;described&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;parameter&nbsp;file.&nbsp;&nbsp;In&nbsp;general,&nbsp;this&nbsp;parameter&nbsp;file&nbsp;would&nbsp;be&nbsp;the&nbsp;same<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;you&nbsp;used&nbsp;for&nbsp;generating&nbsp;the&nbsp;training&nbsp;data.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
<font size=+2 color="red">HOW&nbsp;THE&nbsp;CLASSIFICATION&nbsp;RESULTS&nbsp;ARE&nbsp;DISPLAYED<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;It&nbsp;depends&nbsp;on&nbsp;whether&nbsp;you&nbsp;apply&nbsp;the&nbsp;classifier&nbsp;at&nbsp;once&nbsp;to&nbsp;all&nbsp;the&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;in&nbsp;a&nbsp;file,&nbsp;or&nbsp;whether&nbsp;you&nbsp;feed&nbsp;one&nbsp;data&nbsp;vector&nbsp;at&nbsp;a&nbsp;time&nbsp;into<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;classifier.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;In&nbsp;general,&nbsp;the&nbsp;classifier&nbsp;returns&nbsp;soft&nbsp;classification&nbsp;for&nbsp;a&nbsp;test&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;vector.&nbsp;&nbsp;What&nbsp;that&nbsp;means&nbsp;is&nbsp;that,&nbsp;in&nbsp;general,&nbsp;the&nbsp;classifier&nbsp;will&nbsp;list<br>
&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;the&nbsp;classes&nbsp;to&nbsp;which&nbsp;a&nbsp;given&nbsp;data&nbsp;vector&nbsp;could&nbsp;belong&nbsp;and&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;probability&nbsp;of&nbsp;each&nbsp;such&nbsp;class&nbsp;label&nbsp;for&nbsp;the&nbsp;data&nbsp;vector.&nbsp;Run&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;examples&nbsp;scripts&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;to&nbsp;see&nbsp;how&nbsp;the&nbsp;output&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;classification&nbsp;can&nbsp;be&nbsp;displayed.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;large&nbsp;test&nbsp;datasets,&nbsp;you&nbsp;would&nbsp;obviously&nbsp;want&nbsp;to&nbsp;process&nbsp;an&nbsp;entire<br>
&nbsp;&nbsp;&nbsp;&nbsp;file&nbsp;of&nbsp;test&nbsp;data&nbsp;at&nbsp;a&nbsp;time.&nbsp;&nbsp;For&nbsp;the&nbsp;case&nbsp;of&nbsp;purely&nbsp;symbolic&nbsp;data,&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;best&nbsp;way&nbsp;to&nbsp;do&nbsp;this&nbsp;is&nbsp;to&nbsp;follow&nbsp;my&nbsp;script<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classify_test_data_in_a_file.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;'Examples'&nbsp;directory.&nbsp;&nbsp;This&nbsp;script&nbsp;requires&nbsp;three&nbsp;command-line<br>
&nbsp;&nbsp;&nbsp;&nbsp;arguments,&nbsp;the&nbsp;first&nbsp;argument&nbsp;names&nbsp;the&nbsp;training&nbsp;datafile,&nbsp;the&nbsp;second<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;test&nbsp;datafile,&nbsp;and&nbsp;the&nbsp;third&nbsp;in&nbsp;which&nbsp;the&nbsp;classification&nbsp;results<br>
&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;deposited.&nbsp;&nbsp;The&nbsp;test&nbsp;datafile&nbsp;must&nbsp;mention&nbsp;the&nbsp;order&nbsp;in&nbsp;which<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;features&nbsp;values&nbsp;are&nbsp;presented.&nbsp;&nbsp;For&nbsp;an&nbsp;example,&nbsp;see&nbsp;the&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;'testdata.dat'&nbsp;in&nbsp;the&nbsp;'Examples'&nbsp;directory.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;With&nbsp;regard&nbsp;to&nbsp;the&nbsp;soft&nbsp;classifications&nbsp;returned&nbsp;by&nbsp;this&nbsp;classifier,&nbsp;if<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;probability&nbsp;distributions&nbsp;for&nbsp;the&nbsp;different&nbsp;classes&nbsp;overlap&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;underlying&nbsp;feature&nbsp;space,&nbsp;you&nbsp;would&nbsp;want&nbsp;the&nbsp;classifier&nbsp;to&nbsp;return&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;applicable&nbsp;class&nbsp;labels&nbsp;for&nbsp;a&nbsp;data&nbsp;vector&nbsp;along&nbsp;with&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;corresponding&nbsp;class&nbsp;probabilities.&nbsp;&nbsp;Another&nbsp;reason&nbsp;for&nbsp;why&nbsp;the&nbsp;decision<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree&nbsp;classifier&nbsp;may&nbsp;associate&nbsp;significant&nbsp;probabilities&nbsp;with&nbsp;multiple<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;labels&nbsp;is&nbsp;that&nbsp;you&nbsp;used&nbsp;inadequate&nbsp;number&nbsp;of&nbsp;training&nbsp;samples&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;induce&nbsp;the&nbsp;decision&nbsp;tree.&nbsp;&nbsp;The&nbsp;good&nbsp;thing&nbsp;is&nbsp;that&nbsp;the&nbsp;classifier&nbsp;does<br>
&nbsp;&nbsp;&nbsp;&nbsp;not&nbsp;lie&nbsp;to&nbsp;you&nbsp;(unlike,&nbsp;say,&nbsp;a&nbsp;hard&nbsp;classification&nbsp;rule&nbsp;that&nbsp;would<br>
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;a&nbsp;single&nbsp;class&nbsp;label&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;partitioning&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;underlying&nbsp;feature&nbsp;space).&nbsp;&nbsp;The&nbsp;decision&nbsp;tree&nbsp;classifier&nbsp;give&nbsp;you&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;best&nbsp;classification&nbsp;that&nbsp;can&nbsp;be&nbsp;made&nbsp;given&nbsp;the&nbsp;training&nbsp;data&nbsp;you&nbsp;fed<br>
&nbsp;&nbsp;&nbsp;&nbsp;into&nbsp;it.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">THE&nbsp;EXAMPLES&nbsp;DIRECTORY:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;See&nbsp;the&nbsp;'Examples'&nbsp;directory&nbsp;in&nbsp;the&nbsp;distribution&nbsp;for&nbsp;how&nbsp;to&nbsp;construct&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;decision&nbsp;tree,&nbsp;and&nbsp;how&nbsp;to&nbsp;then&nbsp;classify&nbsp;new&nbsp;data&nbsp;using&nbsp;the&nbsp;decision<br>
&nbsp;&nbsp;&nbsp;&nbsp;tree.&nbsp;&nbsp;To&nbsp;become&nbsp;more&nbsp;familiar&nbsp;with&nbsp;the&nbsp;module,&nbsp;run&nbsp;the&nbsp;scripts<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;construct_dt_and_classify_one_sample_case1.py<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;construct_dt_and_classify_one_sample_case2.py<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;construct_dt_and_classify_one_sample_case3.py<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;construct_dt_and_classify_one_sample_case4.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;first&nbsp;script&nbsp;is&nbsp;for&nbsp;the&nbsp;purely&nbsp;symbolic&nbsp;case,&nbsp;the&nbsp;second&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;that&nbsp;involves&nbsp;both&nbsp;numeric&nbsp;and&nbsp;symbolic&nbsp;features,&nbsp;the&nbsp;third&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;case&nbsp;of&nbsp;purely&nbsp;numeric&nbsp;features,&nbsp;and&nbsp;the&nbsp;last&nbsp;for&nbsp;the&nbsp;case&nbsp;when&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;data&nbsp;is&nbsp;synthetically&nbsp;generated&nbsp;by&nbsp;the&nbsp;script<br>
&nbsp;&nbsp;&nbsp;&nbsp;generate_training_data_numeric.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Next&nbsp;run&nbsp;the&nbsp;script&nbsp;as&nbsp;it&nbsp;is<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classify_test_data_in_a_file.py&nbsp;&nbsp;&nbsp;training.dat&nbsp;&nbsp;&nbsp;testdata.dat&nbsp;&nbsp;&nbsp;out.txt<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;call&nbsp;will&nbsp;first&nbsp;construct&nbsp;a&nbsp;decision&nbsp;tree&nbsp;using&nbsp;the&nbsp;training&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;file&nbsp;'training.dat'.&nbsp;&nbsp;It&nbsp;will&nbsp;then&nbsp;calculate&nbsp;the&nbsp;class&nbsp;label&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;each&nbsp;data&nbsp;record&nbsp;in&nbsp;the&nbsp;file&nbsp;'testdata.dat'.&nbsp;&nbsp;The&nbsp;estimated&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;labels&nbsp;will&nbsp;be&nbsp;written&nbsp;out&nbsp;to&nbsp;the&nbsp;file&nbsp;'out.txt'.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;following&nbsp;script&nbsp;in&nbsp;the&nbsp;'Examples'&nbsp;directory&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classify_by_asking_questions.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;shows&nbsp;how&nbsp;you&nbsp;can&nbsp;use&nbsp;a&nbsp;decision-tree&nbsp;classifier&nbsp;interactively.&nbsp;&nbsp;In<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;mode,&nbsp;you&nbsp;first&nbsp;construct&nbsp;the&nbsp;decision&nbsp;tree&nbsp;from&nbsp;the&nbsp;training&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;then&nbsp;the&nbsp;user&nbsp;is&nbsp;prompted&nbsp;for&nbsp;answers&nbsp;to&nbsp;the&nbsp;feature&nbsp;tests&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;nodes&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;'Examples'&nbsp;directory&nbsp;also&nbsp;contains&nbsp;the&nbsp;following&nbsp;scripts:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generate_training_data_numeric.py<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generate_training_data_symbolic.py<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generate_test_data_symbolic.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;show&nbsp;how&nbsp;you&nbsp;can&nbsp;use&nbsp;the&nbsp;module&nbsp;to&nbsp;generate&nbsp;synthetic&nbsp;training&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;test&nbsp;data.&nbsp;&nbsp;Synthetic&nbsp;training&nbsp;and&nbsp;test&nbsp;data&nbsp;are&nbsp;generated&nbsp;according&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;specifications&nbsp;laid&nbsp;out&nbsp;in&nbsp;a&nbsp;parameter&nbsp;file.&nbsp;&nbsp;There&nbsp;are&nbsp;constraints<br>
&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;how&nbsp;the&nbsp;information&nbsp;is&nbsp;laid&nbsp;out&nbsp;in&nbsp;the&nbsp;parameter&nbsp;file.&nbsp;&nbsp;See&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;files&nbsp;`param_numeric.txt'&nbsp;and&nbsp;`param_symbolic.txt'&nbsp;in&nbsp;the&nbsp;'Examples'<br>
&nbsp;&nbsp;&nbsp;&nbsp;directory&nbsp;for&nbsp;how&nbsp;to&nbsp;structure&nbsp;these&nbsp;files.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;Examples&nbsp;directory&nbsp;of&nbsp;Version&nbsp;2.2&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;contains&nbsp;the&nbsp;following&nbsp;two&nbsp;scripts:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;evaluate_training_data1.py<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;evaluate_training_data2.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;illustrate&nbsp;how&nbsp;the&nbsp;Python&nbsp;class&nbsp;<a href="#EvalTrainingData">EvalTrainingData</a>&nbsp;can&nbsp;be&nbsp;used&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;evaluate&nbsp;the&nbsp;quality&nbsp;of&nbsp;your&nbsp;training&nbsp;data&nbsp;(as&nbsp;long&nbsp;as&nbsp;it&nbsp;resides&nbsp;in&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;`.csv'&nbsp;file.)&nbsp;&nbsp;This&nbsp;new&nbsp;class&nbsp;is&nbsp;a&nbsp;subclass&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;class<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;module&nbsp;file.&nbsp;&nbsp;See&nbsp;the&nbsp;README&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;further&nbsp;information&nbsp;regarding&nbsp;these&nbsp;two&nbsp;scripts.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">INSTALLATION:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;class&nbsp;was&nbsp;packaged&nbsp;using&nbsp;Distutils.&nbsp;&nbsp;For&nbsp;installation,<br>
&nbsp;&nbsp;&nbsp;&nbsp;execute&nbsp;the&nbsp;following&nbsp;command-line&nbsp;in&nbsp;the&nbsp;source&nbsp;directory&nbsp;(this&nbsp;is&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;directory&nbsp;that&nbsp;contains&nbsp;the&nbsp;setup.py&nbsp;file&nbsp;after&nbsp;you&nbsp;have&nbsp;downloaded&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;uncompressed&nbsp;the&nbsp;package):<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;python&nbsp;setup.py&nbsp;install<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;have&nbsp;to&nbsp;have&nbsp;root&nbsp;privileges&nbsp;for&nbsp;this&nbsp;to&nbsp;work.&nbsp;&nbsp;On&nbsp;Linux<br>
&nbsp;&nbsp;&nbsp;&nbsp;distributions,&nbsp;this&nbsp;will&nbsp;install&nbsp;the&nbsp;module&nbsp;file&nbsp;at&nbsp;a&nbsp;location&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;looks&nbsp;like<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/usr/lib/python2.7/dist-packages/<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;do&nbsp;not&nbsp;have&nbsp;root&nbsp;access,&nbsp;you&nbsp;have&nbsp;the&nbsp;option&nbsp;of&nbsp;working&nbsp;directly<br>
&nbsp;&nbsp;&nbsp;&nbsp;off&nbsp;the&nbsp;directory&nbsp;in&nbsp;which&nbsp;you&nbsp;downloaded&nbsp;the&nbsp;software&nbsp;by&nbsp;simply<br>
&nbsp;&nbsp;&nbsp;&nbsp;placing&nbsp;the&nbsp;following&nbsp;statements&nbsp;at&nbsp;the&nbsp;top&nbsp;of&nbsp;your&nbsp;scripts&nbsp;that&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;class:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;sys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sys.path.append(&nbsp;"pathname_to_DecisionTree_directory"&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;To&nbsp;uninstall&nbsp;the&nbsp;module,&nbsp;simply&nbsp;delete&nbsp;the&nbsp;source&nbsp;directory,&nbsp;locate<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a>&nbsp;module&nbsp;was&nbsp;installed&nbsp;with&nbsp;"locate&nbsp;<a href="#DecisionTree">DecisionTree</a>"<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;delete&nbsp;those&nbsp;files.&nbsp;&nbsp;As&nbsp;mentioned&nbsp;above,&nbsp;the&nbsp;full&nbsp;pathname&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;installed&nbsp;version&nbsp;is&nbsp;likely&nbsp;to&nbsp;look&nbsp;like<br>
&nbsp;&nbsp;&nbsp;&nbsp;/usr/lib/python2.7/dist-packages/<a href="#DecisionTree">DecisionTree</a>*<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;want&nbsp;to&nbsp;carry&nbsp;out&nbsp;a&nbsp;non-standard&nbsp;install&nbsp;of&nbsp;the&nbsp;<a href="#DecisionTree">DecisionTree</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;module,&nbsp;look&nbsp;up&nbsp;the&nbsp;on-line&nbsp;information&nbsp;on&nbsp;Disutils&nbsp;by&nbsp;pointing&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;browser&nbsp;to<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://docs.python.org/dist/dist.html">http://docs.python.org/dist/dist.html</a><br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">BUGS:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Please&nbsp;notify&nbsp;the&nbsp;author&nbsp;if&nbsp;you&nbsp;encounter&nbsp;any&nbsp;bugs.&nbsp;&nbsp;When&nbsp;sending<br>
&nbsp;&nbsp;&nbsp;&nbsp;email,&nbsp;please&nbsp;place&nbsp;the&nbsp;string&nbsp;'<a href="#DecisionTree">DecisionTree</a>'&nbsp;in&nbsp;the&nbsp;subject&nbsp;line.<br>
&nbsp;<br>
&nbsp;<br>
<font size=+2 color="red">ACKNOWLEDGMENTS:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;importance&nbsp;of&nbsp;the&nbsp;'sentiment'&nbsp;feature&nbsp;in&nbsp;the&nbsp;"What&nbsp;Practical&nbsp;Problem<br>
&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;Solved&nbsp;by&nbsp;this&nbsp;Module"&nbsp;section&nbsp;was&nbsp;mentioned&nbsp;to&nbsp;the&nbsp;author&nbsp;by&nbsp;John<br>
&nbsp;&nbsp;&nbsp;&nbsp;Gorup.&nbsp;&nbsp;Thanks&nbsp;John.<br>
&nbsp;<br>
<font size=+2 color="red">AUTHOR:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Avinash&nbsp;Kak,&nbsp;kak@purdue.edu<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;send&nbsp;email,&nbsp;please&nbsp;place&nbsp;the&nbsp;string&nbsp;"<a href="#DecisionTree">DecisionTree</a>"&nbsp;in&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;subject&nbsp;line&nbsp;to&nbsp;get&nbsp;past&nbsp;my&nbsp;spam&nbsp;filter.<br>
&nbsp;<br>
<font size=+2 color="red">COPYRIGHT:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Python&nbsp;Software&nbsp;Foundation&nbsp;License<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Copyright&nbsp;2013&nbsp;Avinash&nbsp;Kak</tt></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Imported Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="functools.html">functools</a><br>
<a href="itertools.html">itertools</a><br>
</td><td width="25%" valign=top><a href="math.html">math</a><br>
<a href="operator.html">operator</a><br>
</td><td width="25%" valign=top><a href="re.html">re</a><br>
<a href="sys.html">sys</a><br>
</td><td width="25%" valign=top></td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="__builtin__.html#object">__builtin__.object</a>
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="DecisionTree.html#DTNode">DTNode</a>
</font></dt><dt><font face="helvetica, arial"><a href="DecisionTree.html#DecisionTree">DecisionTree</a>
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="DecisionTree.html#EvalTrainingData">EvalTrainingData</a>
</font></dt></dl>
</dd>
<dt><font face="helvetica, arial"><a href="DecisionTree.html#TestDataGeneratorSymbolic">TestDataGeneratorSymbolic</a>
</font></dt><dt><font face="helvetica, arial"><a href="DecisionTree.html#TrainingDataGeneratorNumeric">TrainingDataGeneratorNumeric</a>
</font></dt><dt><font face="helvetica, arial"><a href="DecisionTree.html#TrainingDataGeneratorSymbolic">TrainingDataGeneratorSymbolic</a>
</font></dt></dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="DTNode">class <strong>DTNode</strong></a>(<a href="__builtin__.html#object">__builtin__.object</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>The&nbsp;nodes&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;are&nbsp;instances&nbsp;of&nbsp;this&nbsp;class:<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%">Methods defined here:<br>
<dl><dt><a name="DTNode-__init__"><strong>__init__</strong></a>(self, feature, entropy, class_probabilities, branch_features_and_values_or_thresholds, root_or_not<font color="#909090">=None</font>)</dt></dl>

<dl><dt><a name="DTNode-add_child_link"><strong>add_child_link</strong></a>(self, new_node)</dt></dl>

<dl><dt><a name="DTNode-delete_all_links"><strong>delete_all_links</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-display_decision_tree"><strong>display_decision_tree</strong></a>(self, offset)</dt></dl>

<dl><dt><a name="DTNode-display_node"><strong>display_node</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-get_branch_features_and_values_or_thresholds"><strong>get_branch_features_and_values_or_thresholds</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-get_children"><strong>get_children</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-get_class_probabilities"><strong>get_class_probabilities</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-get_feature"><strong>get_feature</strong></a>(self)</dt><dd><tt>Returns&nbsp;the&nbsp;feature&nbsp;test&nbsp;at&nbsp;the&nbsp;current&nbsp;node</tt></dd></dl>

<dl><dt><a name="DTNode-get_next_serial_num"><strong>get_next_serial_num</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-get_node_entropy"><strong>get_node_entropy</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-get_serial_num"><strong>get_serial_num</strong></a>(self)</dt></dl>

<dl><dt><a name="DTNode-set_feature"><strong>set_feature</strong></a>(self, feature)</dt></dl>

<hr>
Static methods defined here:<br>
<dl><dt><a name="DTNode-get_class_names"><strong>get_class_names</strong></a>()</dt></dl>

<dl><dt><a name="DTNode-how_many_nodes"><strong>how_many_nodes</strong></a>()</dt></dl>

<dl><dt><a name="DTNode-initialize_DTNode_class"><strong>initialize_DTNode_class</strong></a>()</dt></dl>

<dl><dt><a name="DTNode-set_class_names"><strong>set_class_names</strong></a>(class_names_list)</dt></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>class_names</strong> = None</dl>

<dl><dt><strong>nodes_created</strong> = -1</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="DecisionTree">class <strong>DecisionTree</strong></a>(<a href="__builtin__.html#object">__builtin__.object</a>)</font></td></tr>
    
<tr><td bgcolor="#ffc8d8"><tt>&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%">Methods defined here:<br>
<dl><dt><a name="DecisionTree-__init__"><strong>__init__</strong></a>(self, *args, **kwargs)</dt></dl>

<dl><dt><a name="DecisionTree-best_feature_calculator"><strong>best_feature_calculator</strong></a>(self, features_and_values_or_thresholds_on_branch, existing_node_entropy)</dt><dd><tt>This&nbsp;is&nbsp;the&nbsp;heart&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;constructor.&nbsp;&nbsp;Its&nbsp;main&nbsp;job&nbsp;is&nbsp;to<br>
figure&nbsp;out&nbsp;the&nbsp;best&nbsp;feature&nbsp;to&nbsp;use&nbsp;for&nbsp;partitioning&nbsp;the&nbsp;training&nbsp;data&nbsp;samples<br>
that&nbsp;correspond&nbsp;to&nbsp;the&nbsp;current&nbsp;node.&nbsp;&nbsp;The&nbsp;search&nbsp;for&nbsp;the&nbsp;best&nbsp;feature&nbsp;is<br>
carried&nbsp;out&nbsp;differently&nbsp;for&nbsp;symbolic&nbsp;features&nbsp;and&nbsp;for&nbsp;numeric&nbsp;features.&nbsp;&nbsp;For<br>
a&nbsp;symbolic&nbsp;feature,&nbsp;the&nbsp;method&nbsp;estimates&nbsp;the&nbsp;entropy&nbsp;for&nbsp;each&nbsp;value&nbsp;of&nbsp;the<br>
feature&nbsp;and&nbsp;then&nbsp;averages&nbsp;out&nbsp;these&nbsp;entropies&nbsp;as&nbsp;a&nbsp;measure&nbsp;of&nbsp;the<br>
discriminatory&nbsp;power&nbsp;of&nbsp;that&nbsp;features.&nbsp;&nbsp;For&nbsp;a&nbsp;numeric&nbsp;feature,&nbsp;on&nbsp;the&nbsp;other<br>
hand,&nbsp;it&nbsp;estimates&nbsp;the&nbsp;entropy&nbsp;reduction&nbsp;that&nbsp;can&nbsp;be&nbsp;achieved&nbsp;if&nbsp;we&nbsp;were&nbsp;to<br>
partition&nbsp;the&nbsp;set&nbsp;of&nbsp;training&nbsp;samples&nbsp;at&nbsp;each&nbsp;possible&nbsp;threshold&nbsp;for&nbsp;that<br>
numeric&nbsp;feature.&nbsp;&nbsp;For&nbsp;a&nbsp;numeric&nbsp;feature,&nbsp;all&nbsp;possible&nbsp;sampling&nbsp;points<br>
relevant&nbsp;to&nbsp;the&nbsp;node&nbsp;in&nbsp;question&nbsp;are&nbsp;considered&nbsp;as&nbsp;candidates&nbsp;for&nbsp;thresholds.</tt></dd></dl>

<dl><dt><a name="DecisionTree-calculate_class_priors"><strong>calculate_class_priors</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTree-calculate_first_order_probabilities"><strong>calculate_first_order_probabilities</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTree-class_entropy_for_a_given_sequence_of_features_and_values_or_thresholds"><strong>class_entropy_for_a_given_sequence_of_features_and_values_or_thresholds</strong></a>(self, array_of_features_and_values_or_thresholds)</dt></dl>

<dl><dt><a name="DecisionTree-class_entropy_for_greater_than_threshold_for_feature"><strong>class_entropy_for_greater_than_threshold_for_feature</strong></a>(self, array_of_features_and_values_or_thresholds, feature, threshold)</dt></dl>

<dl><dt><a name="DecisionTree-class_entropy_for_less_than_threshold_for_feature"><strong>class_entropy_for_less_than_threshold_for_feature</strong></a>(self, array_of_features_and_values_or_thresholds, feature, threshold)</dt></dl>

<dl><dt><a name="DecisionTree-class_entropy_on_priors"><strong>class_entropy_on_priors</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTree-classify"><strong>classify</strong></a>(self, root_node, features_and_values)</dt><dd><tt>Classifies&nbsp;one&nbsp;test&nbsp;sample&nbsp;at&nbsp;a&nbsp;time&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree&nbsp;constructed&nbsp;from<br>
your&nbsp;training&nbsp;file.&nbsp;&nbsp;The&nbsp;data&nbsp;record&nbsp;for&nbsp;the&nbsp;test&nbsp;sample&nbsp;must&nbsp;be&nbsp;supplied&nbsp;as<br>
shown&nbsp;in&nbsp;the&nbsp;scripts&nbsp;in&nbsp;the&nbsp;`Examples'&nbsp;subdirectory.&nbsp;&nbsp;See&nbsp;the&nbsp;scripts<br>
construct_dt_and_classify_one_sample_caseX.py&nbsp;in&nbsp;that&nbsp;subdirectory.</tt></dd></dl>

<dl><dt><a name="DecisionTree-classify_by_asking_questions"><strong>classify_by_asking_questions</strong></a>(self, root_node)</dt><dd><tt>If&nbsp;you&nbsp;want&nbsp;classification&nbsp;to&nbsp;be&nbsp;carried&nbsp;out&nbsp;by&nbsp;engaging&nbsp;a&nbsp;human&nbsp;user&nbsp;in&nbsp;a<br>
question-answer&nbsp;session,&nbsp;this&nbsp;is&nbsp;the&nbsp;method&nbsp;to&nbsp;use&nbsp;for&nbsp;that&nbsp;purpose.&nbsp;&nbsp;See&nbsp;the<br>
script&nbsp;classify_by_asking_questions.py&nbsp;in&nbsp;the&nbsp;Examples&nbsp;subdirectory&nbsp;for&nbsp;an<br>
illustration&nbsp;of&nbsp;how&nbsp;to&nbsp;do&nbsp;that.</tt></dd></dl>

<dl><dt><a name="DecisionTree-construct_decision_tree_classifier"><strong>construct_decision_tree_classifier</strong></a>(self)</dt><dd><tt>At&nbsp;the&nbsp;root&nbsp;node,&nbsp;we&nbsp;find&nbsp;the&nbsp;best&nbsp;feature&nbsp;that&nbsp;yields&nbsp;the&nbsp;greatest&nbsp;reduction<br>
in&nbsp;class&nbsp;entropy&nbsp;from&nbsp;the&nbsp;entropy&nbsp;based&nbsp;on&nbsp;just&nbsp;class&nbsp;priors.&nbsp;The&nbsp;logic&nbsp;for<br>
finding&nbsp;this&nbsp;feature&nbsp;is&nbsp;different&nbsp;for&nbsp;symbolic&nbsp;features&nbsp;and&nbsp;for&nbsp;numeric<br>
features.&nbsp;&nbsp;That&nbsp;logic&nbsp;is&nbsp;built&nbsp;into&nbsp;the&nbsp;best&nbsp;feature&nbsp;calculator.</tt></dd></dl>

<dl><dt><a name="DecisionTree-determine_data_condition"><strong>determine_data_condition</strong></a>(self)</dt><dd><tt>This&nbsp;method&nbsp;estimates&nbsp;the&nbsp;worst-case&nbsp;fan-out&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;taking&nbsp;into<br>
account&nbsp;the&nbsp;number&nbsp;of&nbsp;values&nbsp;(and&nbsp;therefore&nbsp;the&nbsp;number&nbsp;of&nbsp;branches&nbsp;emanating<br>
from&nbsp;a&nbsp;node)&nbsp;for&nbsp;the&nbsp;symbolic&nbsp;features.</tt></dd></dl>

<dl><dt><a name="DecisionTree-entropy_scanner_for_a_numeric_feature"><strong>entropy_scanner_for_a_numeric_feature</strong></a>(self, feature)</dt></dl>

<dl><dt><a name="DecisionTree-find_bounded_intervals_for_numeric_features"><strong>find_bounded_intervals_for_numeric_features</strong></a>(self, arr)</dt><dd><tt>Given&nbsp;a&nbsp;list&nbsp;of&nbsp;branch&nbsp;attributes&nbsp;for&nbsp;the&nbsp;numeric&nbsp;features&nbsp;of&nbsp;the&nbsp;form,&nbsp;say,<br>
['g2&lt;1','g2&lt;2','g2&lt;3','age&gt;34','age&gt;36','age&gt;37'],&nbsp;this&nbsp;method&nbsp;returns&nbsp;the<br>
smallest&nbsp;list&nbsp;that&nbsp;is&nbsp;relevant&nbsp;for&nbsp;the&nbsp;purpose&nbsp;of&nbsp;calculating&nbsp;the<br>
probabilities.&nbsp;&nbsp;To&nbsp;explain,&nbsp;the&nbsp;probability&nbsp;that&nbsp;the&nbsp;feature&nbsp;`g2'&nbsp;is&nbsp;less<br>
than&nbsp;1&nbsp;AND,&nbsp;at&nbsp;the&nbsp;same&nbsp;time,&nbsp;less&nbsp;than&nbsp;2,&nbsp;AND,&nbsp;at&nbsp;the&nbsp;same&nbsp;time,&nbsp;less&nbsp;than<br>
3,&nbsp;is&nbsp;the&nbsp;same&nbsp;as&nbsp;the&nbsp;probability&nbsp;that&nbsp;the&nbsp;feature&nbsp;less&nbsp;than&nbsp;1.&nbsp;Similarly,<br>
the&nbsp;probability&nbsp;that&nbsp;'age'&nbsp;is&nbsp;greater&nbsp;than&nbsp;34&nbsp;and&nbsp;also&nbsp;greater&nbsp;than&nbsp;37&nbsp;is&nbsp;the<br>
same&nbsp;as&nbsp;`age'&nbsp;being&nbsp;greater&nbsp;than&nbsp;37.</tt></dd></dl>

<dl><dt><a name="DecisionTree-get_class_names"><strong>get_class_names</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTree-get_training_data"><strong>get_training_data</strong></a>(self)</dt><dd><tt>If&nbsp;your&nbsp;training&nbsp;data&nbsp;is&nbsp;purely&nbsp;symbolic,&nbsp;as&nbsp;in&nbsp;Version&nbsp;1.7.1,&nbsp;you&nbsp;might&nbsp;find<br>
it&nbsp;easier&nbsp;to&nbsp;create&nbsp;a&nbsp;`.dat'&nbsp;file.&nbsp;&nbsp;For&nbsp;purely&nbsp;numeric&nbsp;data,&nbsp;or&nbsp;mixed<br>
symbolic&nbsp;and&nbsp;numeric&nbsp;data,&nbsp;you&nbsp;MUST&nbsp;use&nbsp;a&nbsp;`.csv'&nbsp;file.&nbsp;&nbsp;See&nbsp;examples&nbsp;of&nbsp;these<br>
files&nbsp;in&nbsp;the&nbsp;`Examples'&nbsp;subdirectory.</tt></dd></dl>

<dl><dt><a name="DecisionTree-get_training_data_from_csv"><strong>get_training_data_from_csv</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTree-get_training_data_from_dat"><strong>get_training_data_from_dat</strong></a>(self)</dt><dd><tt>Meant&nbsp;for&nbsp;purely&nbsp;symbolic&nbsp;data&nbsp;(as&nbsp;in&nbsp;all&nbsp;versions&nbsp;up&nbsp;to&nbsp;v.&nbsp;1.7.1)</tt></dd></dl>

<dl><dt><a name="DecisionTree-interactive_recursive_descent_for_classification"><strong>interactive_recursive_descent_for_classification</strong></a>(self, node, answer, scratchpad_for_numerics)</dt></dl>

<dl><dt><a name="DecisionTree-prior_probability_for_class"><strong>prior_probability_for_class</strong></a>(self, class_name)</dt></dl>

<dl><dt><a name="DecisionTree-probability_of_a_class_given_sequence_of_features_and_values_or_thresholds"><strong>probability_of_a_class_given_sequence_of_features_and_values_or_thresholds</strong></a>(self, class_name, array_of_features_and_values_or_thresholds)</dt></dl>

<dl><dt><a name="DecisionTree-probability_of_a_sequence_of_features_and_values_or_thresholds"><strong>probability_of_a_sequence_of_features_and_values_or_thresholds</strong></a>(self, array_of_features_and_values_or_thresholds)</dt><dd><tt>This&nbsp;method&nbsp;requires&nbsp;that&nbsp;all&nbsp;truly&nbsp;numeric&nbsp;types&nbsp;only&nbsp;be&nbsp;expressed&nbsp;as&nbsp;'&lt;'&nbsp;or&nbsp;'&gt;'<br>
constructs&nbsp;in&nbsp;the&nbsp;array&nbsp;of&nbsp;branch&nbsp;features&nbsp;and&nbsp;thresholds</tt></dd></dl>

<dl><dt><a name="DecisionTree-probability_of_a_sequence_of_features_and_values_or_thresholds_given_class"><strong>probability_of_a_sequence_of_features_and_values_or_thresholds_given_class</strong></a>(self, array_of_features_and_values_or_thresholds, class_name)</dt><dd><tt>This&nbsp;method&nbsp;requires&nbsp;that&nbsp;all&nbsp;truly&nbsp;numeric&nbsp;types&nbsp;only&nbsp;be&nbsp;expressed&nbsp;as&nbsp;'&lt;'&nbsp;or&nbsp;'&gt;'<br>
constructs&nbsp;in&nbsp;the&nbsp;array&nbsp;of&nbsp;branch&nbsp;features&nbsp;and&nbsp;thresholds</tt></dd></dl>

<dl><dt><a name="DecisionTree-probability_of_feature_less_than_threshold"><strong>probability_of_feature_less_than_threshold</strong></a>(self, feature_name, threshold)</dt></dl>

<dl><dt><a name="DecisionTree-probability_of_feature_less_than_threshold_given_class"><strong>probability_of_feature_less_than_threshold_given_class</strong></a>(self, feature_name, threshold, class_name)</dt></dl>

<dl><dt><a name="DecisionTree-probability_of_feature_value"><strong>probability_of_feature_value</strong></a>(self, feature_name, value)</dt></dl>

<dl><dt><a name="DecisionTree-probability_of_feature_value_given_class"><strong>probability_of_feature_value_given_class</strong></a>(self, feature_name, feature_value, class_name)</dt></dl>

<dl><dt><a name="DecisionTree-recursive_descent"><strong>recursive_descent</strong></a>(self, node)</dt><dd><tt>After&nbsp;the&nbsp;root&nbsp;node&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;is&nbsp;constructed&nbsp;by&nbsp;the&nbsp;previous<br>
methods,&nbsp;we&nbsp;invoke&nbsp;this&nbsp;method&nbsp;recursively&nbsp;to&nbsp;create&nbsp;the&nbsp;rest&nbsp;of&nbsp;the&nbsp;tree.<br>
At&nbsp;each&nbsp;node,&nbsp;we&nbsp;find&nbsp;the&nbsp;feature&nbsp;that&nbsp;achieves&nbsp;the&nbsp;largest&nbsp;entropy&nbsp;reduction<br>
with&nbsp;regard&nbsp;to&nbsp;the&nbsp;partitioning&nbsp;of&nbsp;the&nbsp;training&nbsp;data&nbsp;samples&nbsp;that&nbsp;correspond<br>
to&nbsp;that&nbsp;node.</tt></dd></dl>

<dl><dt><a name="DecisionTree-recursive_descent_for_classification"><strong>recursive_descent_for_classification</strong></a>(self, node, feature_and_values, answer)</dt></dl>

<dl><dt><a name="DecisionTree-show_training_data"><strong>show_training_data</strong></a>(self)</dt></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="EvalTrainingData">class <strong>EvalTrainingData</strong></a>(<a href="DecisionTree.html#DecisionTree">DecisionTree</a>)</font></td></tr>
    
<tr><td bgcolor="#ffc8d8"><tt>&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="DecisionTree.html#EvalTrainingData">EvalTrainingData</a></dd>
<dd><a href="DecisionTree.html#DecisionTree">DecisionTree</a></dd>
<dd><a href="__builtin__.html#object">__builtin__.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="EvalTrainingData-__init__"><strong>__init__</strong></a>(self, *args, **kwargs)</dt></dl>

<dl><dt><a name="EvalTrainingData-evaluate_training_data"><strong>evaluate_training_data</strong></a>(self)</dt></dl>

<hr>
Methods inherited from <a href="DecisionTree.html#DecisionTree">DecisionTree</a>:<br>
<dl><dt><a name="EvalTrainingData-best_feature_calculator"><strong>best_feature_calculator</strong></a>(self, features_and_values_or_thresholds_on_branch, existing_node_entropy)</dt><dd><tt>This&nbsp;is&nbsp;the&nbsp;heart&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;constructor.&nbsp;&nbsp;Its&nbsp;main&nbsp;job&nbsp;is&nbsp;to<br>
figure&nbsp;out&nbsp;the&nbsp;best&nbsp;feature&nbsp;to&nbsp;use&nbsp;for&nbsp;partitioning&nbsp;the&nbsp;training&nbsp;data&nbsp;samples<br>
that&nbsp;correspond&nbsp;to&nbsp;the&nbsp;current&nbsp;node.&nbsp;&nbsp;The&nbsp;search&nbsp;for&nbsp;the&nbsp;best&nbsp;feature&nbsp;is<br>
carried&nbsp;out&nbsp;differently&nbsp;for&nbsp;symbolic&nbsp;features&nbsp;and&nbsp;for&nbsp;numeric&nbsp;features.&nbsp;&nbsp;For<br>
a&nbsp;symbolic&nbsp;feature,&nbsp;the&nbsp;method&nbsp;estimates&nbsp;the&nbsp;entropy&nbsp;for&nbsp;each&nbsp;value&nbsp;of&nbsp;the<br>
feature&nbsp;and&nbsp;then&nbsp;averages&nbsp;out&nbsp;these&nbsp;entropies&nbsp;as&nbsp;a&nbsp;measure&nbsp;of&nbsp;the<br>
discriminatory&nbsp;power&nbsp;of&nbsp;that&nbsp;features.&nbsp;&nbsp;For&nbsp;a&nbsp;numeric&nbsp;feature,&nbsp;on&nbsp;the&nbsp;other<br>
hand,&nbsp;it&nbsp;estimates&nbsp;the&nbsp;entropy&nbsp;reduction&nbsp;that&nbsp;can&nbsp;be&nbsp;achieved&nbsp;if&nbsp;we&nbsp;were&nbsp;to<br>
partition&nbsp;the&nbsp;set&nbsp;of&nbsp;training&nbsp;samples&nbsp;at&nbsp;each&nbsp;possible&nbsp;threshold&nbsp;for&nbsp;that<br>
numeric&nbsp;feature.&nbsp;&nbsp;For&nbsp;a&nbsp;numeric&nbsp;feature,&nbsp;all&nbsp;possible&nbsp;sampling&nbsp;points<br>
relevant&nbsp;to&nbsp;the&nbsp;node&nbsp;in&nbsp;question&nbsp;are&nbsp;considered&nbsp;as&nbsp;candidates&nbsp;for&nbsp;thresholds.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-calculate_class_priors"><strong>calculate_class_priors</strong></a>(self)</dt></dl>

<dl><dt><a name="EvalTrainingData-calculate_first_order_probabilities"><strong>calculate_first_order_probabilities</strong></a>(self)</dt></dl>

<dl><dt><a name="EvalTrainingData-class_entropy_for_a_given_sequence_of_features_and_values_or_thresholds"><strong>class_entropy_for_a_given_sequence_of_features_and_values_or_thresholds</strong></a>(self, array_of_features_and_values_or_thresholds)</dt></dl>

<dl><dt><a name="EvalTrainingData-class_entropy_for_greater_than_threshold_for_feature"><strong>class_entropy_for_greater_than_threshold_for_feature</strong></a>(self, array_of_features_and_values_or_thresholds, feature, threshold)</dt></dl>

<dl><dt><a name="EvalTrainingData-class_entropy_for_less_than_threshold_for_feature"><strong>class_entropy_for_less_than_threshold_for_feature</strong></a>(self, array_of_features_and_values_or_thresholds, feature, threshold)</dt></dl>

<dl><dt><a name="EvalTrainingData-class_entropy_on_priors"><strong>class_entropy_on_priors</strong></a>(self)</dt></dl>

<dl><dt><a name="EvalTrainingData-classify"><strong>classify</strong></a>(self, root_node, features_and_values)</dt><dd><tt>Classifies&nbsp;one&nbsp;test&nbsp;sample&nbsp;at&nbsp;a&nbsp;time&nbsp;using&nbsp;the&nbsp;decision&nbsp;tree&nbsp;constructed&nbsp;from<br>
your&nbsp;training&nbsp;file.&nbsp;&nbsp;The&nbsp;data&nbsp;record&nbsp;for&nbsp;the&nbsp;test&nbsp;sample&nbsp;must&nbsp;be&nbsp;supplied&nbsp;as<br>
shown&nbsp;in&nbsp;the&nbsp;scripts&nbsp;in&nbsp;the&nbsp;`Examples'&nbsp;subdirectory.&nbsp;&nbsp;See&nbsp;the&nbsp;scripts<br>
construct_dt_and_classify_one_sample_caseX.py&nbsp;in&nbsp;that&nbsp;subdirectory.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-classify_by_asking_questions"><strong>classify_by_asking_questions</strong></a>(self, root_node)</dt><dd><tt>If&nbsp;you&nbsp;want&nbsp;classification&nbsp;to&nbsp;be&nbsp;carried&nbsp;out&nbsp;by&nbsp;engaging&nbsp;a&nbsp;human&nbsp;user&nbsp;in&nbsp;a<br>
question-answer&nbsp;session,&nbsp;this&nbsp;is&nbsp;the&nbsp;method&nbsp;to&nbsp;use&nbsp;for&nbsp;that&nbsp;purpose.&nbsp;&nbsp;See&nbsp;the<br>
script&nbsp;classify_by_asking_questions.py&nbsp;in&nbsp;the&nbsp;Examples&nbsp;subdirectory&nbsp;for&nbsp;an<br>
illustration&nbsp;of&nbsp;how&nbsp;to&nbsp;do&nbsp;that.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-construct_decision_tree_classifier"><strong>construct_decision_tree_classifier</strong></a>(self)</dt><dd><tt>At&nbsp;the&nbsp;root&nbsp;node,&nbsp;we&nbsp;find&nbsp;the&nbsp;best&nbsp;feature&nbsp;that&nbsp;yields&nbsp;the&nbsp;greatest&nbsp;reduction<br>
in&nbsp;class&nbsp;entropy&nbsp;from&nbsp;the&nbsp;entropy&nbsp;based&nbsp;on&nbsp;just&nbsp;class&nbsp;priors.&nbsp;The&nbsp;logic&nbsp;for<br>
finding&nbsp;this&nbsp;feature&nbsp;is&nbsp;different&nbsp;for&nbsp;symbolic&nbsp;features&nbsp;and&nbsp;for&nbsp;numeric<br>
features.&nbsp;&nbsp;That&nbsp;logic&nbsp;is&nbsp;built&nbsp;into&nbsp;the&nbsp;best&nbsp;feature&nbsp;calculator.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-determine_data_condition"><strong>determine_data_condition</strong></a>(self)</dt><dd><tt>This&nbsp;method&nbsp;estimates&nbsp;the&nbsp;worst-case&nbsp;fan-out&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;taking&nbsp;into<br>
account&nbsp;the&nbsp;number&nbsp;of&nbsp;values&nbsp;(and&nbsp;therefore&nbsp;the&nbsp;number&nbsp;of&nbsp;branches&nbsp;emanating<br>
from&nbsp;a&nbsp;node)&nbsp;for&nbsp;the&nbsp;symbolic&nbsp;features.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-entropy_scanner_for_a_numeric_feature"><strong>entropy_scanner_for_a_numeric_feature</strong></a>(self, feature)</dt></dl>

<dl><dt><a name="EvalTrainingData-find_bounded_intervals_for_numeric_features"><strong>find_bounded_intervals_for_numeric_features</strong></a>(self, arr)</dt><dd><tt>Given&nbsp;a&nbsp;list&nbsp;of&nbsp;branch&nbsp;attributes&nbsp;for&nbsp;the&nbsp;numeric&nbsp;features&nbsp;of&nbsp;the&nbsp;form,&nbsp;say,<br>
['g2&lt;1','g2&lt;2','g2&lt;3','age&gt;34','age&gt;36','age&gt;37'],&nbsp;this&nbsp;method&nbsp;returns&nbsp;the<br>
smallest&nbsp;list&nbsp;that&nbsp;is&nbsp;relevant&nbsp;for&nbsp;the&nbsp;purpose&nbsp;of&nbsp;calculating&nbsp;the<br>
probabilities.&nbsp;&nbsp;To&nbsp;explain,&nbsp;the&nbsp;probability&nbsp;that&nbsp;the&nbsp;feature&nbsp;`g2'&nbsp;is&nbsp;less<br>
than&nbsp;1&nbsp;AND,&nbsp;at&nbsp;the&nbsp;same&nbsp;time,&nbsp;less&nbsp;than&nbsp;2,&nbsp;AND,&nbsp;at&nbsp;the&nbsp;same&nbsp;time,&nbsp;less&nbsp;than<br>
3,&nbsp;is&nbsp;the&nbsp;same&nbsp;as&nbsp;the&nbsp;probability&nbsp;that&nbsp;the&nbsp;feature&nbsp;less&nbsp;than&nbsp;1.&nbsp;Similarly,<br>
the&nbsp;probability&nbsp;that&nbsp;'age'&nbsp;is&nbsp;greater&nbsp;than&nbsp;34&nbsp;and&nbsp;also&nbsp;greater&nbsp;than&nbsp;37&nbsp;is&nbsp;the<br>
same&nbsp;as&nbsp;`age'&nbsp;being&nbsp;greater&nbsp;than&nbsp;37.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-get_class_names"><strong>get_class_names</strong></a>(self)</dt></dl>

<dl><dt><a name="EvalTrainingData-get_training_data"><strong>get_training_data</strong></a>(self)</dt><dd><tt>If&nbsp;your&nbsp;training&nbsp;data&nbsp;is&nbsp;purely&nbsp;symbolic,&nbsp;as&nbsp;in&nbsp;Version&nbsp;1.7.1,&nbsp;you&nbsp;might&nbsp;find<br>
it&nbsp;easier&nbsp;to&nbsp;create&nbsp;a&nbsp;`.dat'&nbsp;file.&nbsp;&nbsp;For&nbsp;purely&nbsp;numeric&nbsp;data,&nbsp;or&nbsp;mixed<br>
symbolic&nbsp;and&nbsp;numeric&nbsp;data,&nbsp;you&nbsp;MUST&nbsp;use&nbsp;a&nbsp;`.csv'&nbsp;file.&nbsp;&nbsp;See&nbsp;examples&nbsp;of&nbsp;these<br>
files&nbsp;in&nbsp;the&nbsp;`Examples'&nbsp;subdirectory.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-get_training_data_from_csv"><strong>get_training_data_from_csv</strong></a>(self)</dt></dl>

<dl><dt><a name="EvalTrainingData-get_training_data_from_dat"><strong>get_training_data_from_dat</strong></a>(self)</dt><dd><tt>Meant&nbsp;for&nbsp;purely&nbsp;symbolic&nbsp;data&nbsp;(as&nbsp;in&nbsp;all&nbsp;versions&nbsp;up&nbsp;to&nbsp;v.&nbsp;1.7.1)</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-interactive_recursive_descent_for_classification"><strong>interactive_recursive_descent_for_classification</strong></a>(self, node, answer, scratchpad_for_numerics)</dt></dl>

<dl><dt><a name="EvalTrainingData-prior_probability_for_class"><strong>prior_probability_for_class</strong></a>(self, class_name)</dt></dl>

<dl><dt><a name="EvalTrainingData-probability_of_a_class_given_sequence_of_features_and_values_or_thresholds"><strong>probability_of_a_class_given_sequence_of_features_and_values_or_thresholds</strong></a>(self, class_name, array_of_features_and_values_or_thresholds)</dt></dl>

<dl><dt><a name="EvalTrainingData-probability_of_a_sequence_of_features_and_values_or_thresholds"><strong>probability_of_a_sequence_of_features_and_values_or_thresholds</strong></a>(self, array_of_features_and_values_or_thresholds)</dt><dd><tt>This&nbsp;method&nbsp;requires&nbsp;that&nbsp;all&nbsp;truly&nbsp;numeric&nbsp;types&nbsp;only&nbsp;be&nbsp;expressed&nbsp;as&nbsp;'&lt;'&nbsp;or&nbsp;'&gt;'<br>
constructs&nbsp;in&nbsp;the&nbsp;array&nbsp;of&nbsp;branch&nbsp;features&nbsp;and&nbsp;thresholds</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-probability_of_a_sequence_of_features_and_values_or_thresholds_given_class"><strong>probability_of_a_sequence_of_features_and_values_or_thresholds_given_class</strong></a>(self, array_of_features_and_values_or_thresholds, class_name)</dt><dd><tt>This&nbsp;method&nbsp;requires&nbsp;that&nbsp;all&nbsp;truly&nbsp;numeric&nbsp;types&nbsp;only&nbsp;be&nbsp;expressed&nbsp;as&nbsp;'&lt;'&nbsp;or&nbsp;'&gt;'<br>
constructs&nbsp;in&nbsp;the&nbsp;array&nbsp;of&nbsp;branch&nbsp;features&nbsp;and&nbsp;thresholds</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-probability_of_feature_less_than_threshold"><strong>probability_of_feature_less_than_threshold</strong></a>(self, feature_name, threshold)</dt></dl>

<dl><dt><a name="EvalTrainingData-probability_of_feature_less_than_threshold_given_class"><strong>probability_of_feature_less_than_threshold_given_class</strong></a>(self, feature_name, threshold, class_name)</dt></dl>

<dl><dt><a name="EvalTrainingData-probability_of_feature_value"><strong>probability_of_feature_value</strong></a>(self, feature_name, value)</dt></dl>

<dl><dt><a name="EvalTrainingData-probability_of_feature_value_given_class"><strong>probability_of_feature_value_given_class</strong></a>(self, feature_name, feature_value, class_name)</dt></dl>

<dl><dt><a name="EvalTrainingData-recursive_descent"><strong>recursive_descent</strong></a>(self, node)</dt><dd><tt>After&nbsp;the&nbsp;root&nbsp;node&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree&nbsp;is&nbsp;constructed&nbsp;by&nbsp;the&nbsp;previous<br>
methods,&nbsp;we&nbsp;invoke&nbsp;this&nbsp;method&nbsp;recursively&nbsp;to&nbsp;create&nbsp;the&nbsp;rest&nbsp;of&nbsp;the&nbsp;tree.<br>
At&nbsp;each&nbsp;node,&nbsp;we&nbsp;find&nbsp;the&nbsp;feature&nbsp;that&nbsp;achieves&nbsp;the&nbsp;largest&nbsp;entropy&nbsp;reduction<br>
with&nbsp;regard&nbsp;to&nbsp;the&nbsp;partitioning&nbsp;of&nbsp;the&nbsp;training&nbsp;data&nbsp;samples&nbsp;that&nbsp;correspond<br>
to&nbsp;that&nbsp;node.</tt></dd></dl>

<dl><dt><a name="EvalTrainingData-recursive_descent_for_classification"><strong>recursive_descent_for_classification</strong></a>(self, node, feature_and_values, answer)</dt></dl>

<dl><dt><a name="EvalTrainingData-show_training_data"><strong>show_training_data</strong></a>(self)</dt></dl>

<hr>
Data descriptors inherited from <a href="DecisionTree.html#DecisionTree">DecisionTree</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="TestDataGeneratorSymbolic">class <strong>TestDataGeneratorSymbolic</strong></a>(<a href="__builtin__.html#object">__builtin__.object</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>This&nbsp;convenience&nbsp;class&nbsp;does&nbsp;basically&nbsp;the&nbsp;same&nbsp;thing&nbsp;as&nbsp;the<br>
<a href="#TrainingDataGeneratorSymbolic">TrainingDataGeneratorSymbolic</a>&nbsp;except&nbsp;that&nbsp;it&nbsp;places&nbsp;the&nbsp;class&nbsp;labels&nbsp;for&nbsp;the<br>
sample&nbsp;records&nbsp;in&nbsp;a&nbsp;separate&nbsp;file.&nbsp;&nbsp;Let's&nbsp;say&nbsp;you&nbsp;have&nbsp;already&nbsp;created&nbsp;a&nbsp;DT<br>
classifier&nbsp;and&nbsp;you&nbsp;would&nbsp;like&nbsp;to&nbsp;test&nbsp;its&nbsp;class&nbsp;discriminatory&nbsp;power.&nbsp;&nbsp;You&nbsp;can<br>
use&nbsp;the&nbsp;classifier&nbsp;to&nbsp;calculate&nbsp;the&nbsp;class&nbsp;labels&nbsp;for&nbsp;the&nbsp;data&nbsp;records&nbsp;by&nbsp;the<br>
class&nbsp;shown&nbsp;here.&nbsp;&nbsp;And&nbsp;then&nbsp;you&nbsp;can&nbsp;you&nbsp;can&nbsp;compare&nbsp;those&nbsp;class&nbsp;labels&nbsp;with&nbsp;those<br>
placed&nbsp;originally&nbsp;by&nbsp;this&nbsp;class&nbsp;in&nbsp;a&nbsp;separate&nbsp;file.&nbsp;&nbsp;See&nbsp;the&nbsp;script<br>
generate_test_data_symbolic.py&nbsp;for&nbsp;how&nbsp;to&nbsp;use&nbsp;this&nbsp;class.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%">Methods defined here:<br>
<dl><dt><a name="TestDataGeneratorSymbolic-__init__"><strong>__init__</strong></a>(self, *args, **kwargs)</dt></dl>

<dl><dt><a name="TestDataGeneratorSymbolic-find_longest_value"><strong>find_longest_value</strong></a>(self)</dt></dl>

<dl><dt><a name="TestDataGeneratorSymbolic-gen_test_data"><strong>gen_test_data</strong></a>(self)</dt><dd><tt>This&nbsp;method&nbsp;generates&nbsp;the&nbsp;test&nbsp;data&nbsp;according&nbsp;to&nbsp;the&nbsp;specifications<br>
laid&nbsp;out&nbsp;in&nbsp;the&nbsp;parameter&nbsp;file&nbsp;read&nbsp;by&nbsp;the&nbsp;previous&nbsp;method.</tt></dd></dl>

<dl><dt><a name="TestDataGeneratorSymbolic-read_parameter_file"><strong>read_parameter_file</strong></a>(self)</dt><dd><tt>This&nbsp;methods&nbsp;reads&nbsp;the&nbsp;parameter&nbsp;file&nbsp;for&nbsp;generating&nbsp;the&nbsp;test&nbsp;data.</tt></dd></dl>

<dl><dt><a name="TestDataGeneratorSymbolic-write_test_data_to_file"><strong>write_test_data_to_file</strong></a>(self)</dt></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="TrainingDataGeneratorNumeric">class <strong>TrainingDataGeneratorNumeric</strong></a>(<a href="__builtin__.html#object">__builtin__.object</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>See&nbsp;the&nbsp;example&nbsp;script&nbsp;generate_training_data_numeric.py&nbsp;on&nbsp;how&nbsp;to&nbsp;use&nbsp;this&nbsp;class<br>
for&nbsp;generating&nbsp;your&nbsp;numeric&nbsp;training&nbsp;data.&nbsp;&nbsp;The&nbsp;training&nbsp;data&nbsp;is&nbsp;generator&nbsp;in<br>
accordance&nbsp;with&nbsp;the&nbsp;specifications&nbsp;you&nbsp;place&nbsp;in&nbsp;a&nbsp;parameter&nbsp;file.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%">Methods defined here:<br>
<dl><dt><a name="TrainingDataGeneratorNumeric-__init__"><strong>__init__</strong></a>(self, *args, **kwargs)</dt></dl>

<dl><dt><a name="TrainingDataGeneratorNumeric-gen_numeric_training_data_and_write_to_csv"><strong>gen_numeric_training_data_and_write_to_csv</strong></a>(self)</dt><dd><tt>After&nbsp;the&nbsp;parameter&nbsp;file&nbsp;is&nbsp;parsed&nbsp;by&nbsp;the&nbsp;previous&nbsp;method,&nbsp;this&nbsp;method&nbsp;calls<br>
on&nbsp;`numpy.random.multivariate_normal()'&nbsp;to&nbsp;generate&nbsp;the&nbsp;training&nbsp;data<br>
samples.&nbsp;Your&nbsp;training&nbsp;data&nbsp;can&nbsp;be&nbsp;of&nbsp;any&nbsp;number&nbsp;of&nbsp;of&nbsp;dimensions,&nbsp;can&nbsp;have<br>
any&nbsp;mean,&nbsp;and&nbsp;any&nbsp;covariance.</tt></dd></dl>

<dl><dt><a name="TrainingDataGeneratorNumeric-read_parameter_file_numeric"><strong>read_parameter_file_numeric</strong></a>(self)</dt><dd><tt>The&nbsp;training&nbsp;data&nbsp;generated&nbsp;by&nbsp;an&nbsp;instance&nbsp;of&nbsp;the&nbsp;class<br>
<a href="#TrainingDataGeneratorNumeric">TrainingDataGeneratorNumeric</a>&nbsp;is&nbsp;based&nbsp;on&nbsp;the&nbsp;specs&nbsp;you&nbsp;place&nbsp;in&nbsp;a&nbsp;parameter<br>
that&nbsp;you&nbsp;supply&nbsp;to&nbsp;the&nbsp;class&nbsp;constructor&nbsp;through&nbsp;a&nbsp;constructor&nbsp;variable<br>
called&nbsp;`parameter_file.&nbsp;&nbsp;This&nbsp;method&nbsp;is&nbsp;for&nbsp;parsing&nbsp;the&nbsp;parameter&nbsp;file&nbsp;in<br>
order&nbsp;to&nbsp;order&nbsp;to&nbsp;determine&nbsp;the&nbsp;names&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;the&nbsp;different&nbsp;data<br>
classes,&nbsp;their&nbsp;means,&nbsp;and&nbsp;their&nbsp;variances.</tt></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="TrainingDataGeneratorSymbolic">class <strong>TrainingDataGeneratorSymbolic</strong></a>(<a href="__builtin__.html#object">__builtin__.object</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>See&nbsp;the&nbsp;sample&nbsp;script&nbsp;generate_training_data_symbolic.py&nbsp;for&nbsp;how&nbsp;to&nbsp;use&nbsp;this<br>
class&nbsp;for&nbsp;generating&nbsp;symbolic&nbsp;training&nbsp;data.&nbsp;&nbsp;The&nbsp;data&nbsp;is&nbsp;generated&nbsp;according&nbsp;to<br>
the&nbsp;specifications&nbsp;you&nbsp;place&nbsp;in&nbsp;a&nbsp;parameter&nbsp;file.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%">Methods defined here:<br>
<dl><dt><a name="TrainingDataGeneratorSymbolic-__init__"><strong>__init__</strong></a>(self, *args, **kwargs)</dt></dl>

<dl><dt><a name="TrainingDataGeneratorSymbolic-find_longest_feature_or_value"><strong>find_longest_feature_or_value</strong></a>(self)</dt></dl>

<dl><dt><a name="TrainingDataGeneratorSymbolic-gen_symbolic_training_data"><strong>gen_symbolic_training_data</strong></a>(self)</dt><dd><tt>This&nbsp;method&nbsp;generates&nbsp;the&nbsp;training&nbsp;data&nbsp;according&nbsp;to&nbsp;the&nbsp;specifications<br>
placed&nbsp;in&nbsp;the&nbsp;parameter&nbsp;file&nbsp;that&nbsp;is&nbsp;read&nbsp;by&nbsp;the&nbsp;previous&nbsp;method.</tt></dd></dl>

<dl><dt><a name="TrainingDataGeneratorSymbolic-read_parameter_file_symbolic"><strong>read_parameter_file_symbolic</strong></a>(self)</dt><dd><tt>Read&nbsp;the&nbsp;parameter&nbsp;file&nbsp;for&nbsp;generating&nbsp;symbolic&nbsp;training&nbsp;data.&nbsp;See&nbsp;the&nbsp;script<br>
generate_training_data_symbolic.py&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;for&nbsp;how&nbsp;to&nbsp;pass<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;file&nbsp;to&nbsp;the&nbsp;constructor&nbsp;of&nbsp;the<br>
<a href="#TrainingDataGeneratorSymbolic">TrainingDataGeneratorSymbolic</a>&nbsp;class.</tt></dd></dl>

<dl><dt><a name="TrainingDataGeneratorSymbolic-write_training_data_to_file"><strong>write_training_data_to_file</strong></a>(self)</dt></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#eeaa77">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Functions</strong></big></font></td></tr>
    
<tr><td bgcolor="#eeaa77"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt><a name="-closest_sampling_point"><strong>closest_sampling_point</strong></a>(value, arr)</dt></dl>
 <dl><dt><a name="-convert"><strong>convert</strong></a>(value)</dt></dl>
 <dl><dt><a name="-deep_copy_array"><strong>deep_copy_array</strong></a>(array_in)</dt><dd><tt>Meant&nbsp;only&nbsp;for&nbsp;an&nbsp;array&nbsp;of&nbsp;scalars&nbsp;(no&nbsp;nesting):</tt></dd></dl>
 <dl><dt><a name="-minimum"><strong>minimum</strong></a>(arr)</dt><dd><tt>Returns&nbsp;simultaneously&nbsp;the&nbsp;minimum&nbsp;value&nbsp;and&nbsp;its&nbsp;positional&nbsp;index&nbsp;in&nbsp;an<br>
array.&nbsp;[Could&nbsp;also&nbsp;have&nbsp;used&nbsp;min()&nbsp;and&nbsp;index()&nbsp;defined&nbsp;for&nbsp;Python's<br>
sequence&nbsp;types.]</tt></dd></dl>
 <dl><dt><a name="-sample_index"><strong>sample_index</strong></a>(sample_name)</dt><dd><tt>When&nbsp;the&nbsp;training&nbsp;data&nbsp;is&nbsp;read&nbsp;from&nbsp;a&nbsp;CSV&nbsp;file,&nbsp;we&nbsp;assume&nbsp;that&nbsp;the&nbsp;first&nbsp;column<br>
of&nbsp;each&nbsp;data&nbsp;record&nbsp;contains&nbsp;a&nbsp;unique&nbsp;integer&nbsp;identifier&nbsp;for&nbsp;the&nbsp;record&nbsp;in&nbsp;that<br>
row.&nbsp;This&nbsp;training&nbsp;data&nbsp;is&nbsp;stored&nbsp;in&nbsp;a&nbsp;dictionary&nbsp;whose&nbsp;keys&nbsp;are&nbsp;the&nbsp;prefix<br>
'sample_'&nbsp;followed&nbsp;by&nbsp;the&nbsp;identifying&nbsp;integers.&nbsp;&nbsp;For&nbsp;the&nbsp;data&nbsp;in&nbsp;the&nbsp;old-style<br>
`.dat'&nbsp;files,&nbsp;we&nbsp;assume&nbsp;that&nbsp;each&nbsp;record&nbsp;begins&nbsp;with&nbsp;the&nbsp;string&nbsp;`sample_xx'&nbsp;where<br>
`xx'&nbsp;is&nbsp;a&nbsp;unique&nbsp;integer.&nbsp;&nbsp;In&nbsp;both&nbsp;cases,&nbsp;the&nbsp;purpose&nbsp;of&nbsp;this&nbsp;function&nbsp;is&nbsp;to<br>
return&nbsp;the&nbsp;identifying&nbsp;integer&nbsp;associated&nbsp;with&nbsp;a&nbsp;data&nbsp;record.</tt></dd></dl>
</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>__author__</strong> = 'Avinash Kak (kak@purdue.edu)'<br>
<strong>__copyright__</strong> = '(C) 2013 Avinash Kak. Python Software Foundation.'<br>
<strong>__date__</strong> = '2013-September-5'<br>
<strong>__url__</strong> = 'https://engineering.purdue.edu/kak/distDT/DecisionTree-2.2.1.html'<br>
<strong>__version__</strong> = '2.2.1'</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#7799ee">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Author</strong></big></font></td></tr>
    
<tr><td bgcolor="#7799ee"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%">Avinash&nbsp;Kak&nbsp;(kak@purdue.edu)</td></tr></table>
</body></html><br>
</tt>
</body></html>
